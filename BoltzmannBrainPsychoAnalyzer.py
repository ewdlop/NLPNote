"""
Boltzmann Brain's Superego-Ego-Id Analyzer
åšå°”å…¹æ›¼å¤§è„‘çš„è¶…æˆ‘-è‡ªæˆ‘-æœ¬æˆ‘åˆ†æå™¨

This module implements a psychoanalytic text analysis system that combines:
1. Freudian tripartite model (Id, Ego, Superego) for psychological content analysis
2. Boltzmann brain theory concepts for consciousness coherence and randomness detection
3. Integration with existing NLP evaluation frameworks

The Boltzmann brain concept suggests consciousness emerging from random quantum fluctuations,
while Freudian psychology divides the psyche into:
- Id: primitive impulses and desires
- Ego: reality principle and rational thought
- Superego: moral conscience and social norms

è¿™ä¸ªæ¨¡å—å®ç°äº†ä¸€ä¸ªå¿ƒç†åˆ†ææ–‡æœ¬åˆ†æç³»ç»Ÿï¼Œç»“åˆäº†ï¼š
1. å¼—æ´›ä¼Šå¾·ä¸‰åˆ†æ¨¡å‹ï¼ˆæœ¬æˆ‘ã€è‡ªæˆ‘ã€è¶…æˆ‘ï¼‰ç”¨äºå¿ƒç†å†…å®¹åˆ†æ
2. åšå°”å…¹æ›¼å¤§è„‘ç†è®ºæ¦‚å¿µç”¨äºæ„è¯†è¿è´¯æ€§å’Œéšæœºæ€§æ£€æµ‹
3. ä¸ç°æœ‰NLPè¯„ä¼°æ¡†æ¶çš„é›†æˆ
"""

import re
import math
import random
from typing import Dict, List, Any, Tuple, Optional, Union
from dataclasses import dataclass
from enum import Enum
from collections import Counter, defaultdict

# Try to import optional dependencies gracefully
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

try:
    import nltk
    from nltk.tokenize import word_tokenize, sent_tokenize
    from nltk.corpus import wordnet
    from nltk.sentiment import SentimentIntensityAnalyzer
    NLTK_AVAILABLE = True
except ImportError:
    NLTK_AVAILABLE = False
    nltk = None

try:
    from HumanExpressionEvaluator import EvaluationDimension, ExpressionContext, EvaluationResult
    HUMAN_EVALUATOR_AVAILABLE = True
except ImportError:
    # Define minimal classes if main evaluator not available
    HUMAN_EVALUATOR_AVAILABLE = False
    
    class EvaluationDimension(Enum):
        PSYCHOLOGICAL = "psychological"
        CONSCIOUSNESS = "consciousness"
        BOLTZMANN = "boltzmann"
    
    @dataclass
    class ExpressionContext:
        speaker: str = "unknown"
        emotional_state: str = "neutral"
        formality_level: str = "neutral"
    
    @dataclass
    class EvaluationResult:
        dimension: EvaluationDimension
        score: float
        confidence: float
        explanation: str
        sub_scores: Dict[str, float] = None


class PsychodynamicComponent(Enum):
    """å¼—æ´›ä¼Šå¾·å¿ƒç†ç»“æ„ç»„ä»¶ (Freudian Psychic Components)"""
    ID = "id"  # æœ¬æˆ‘ï¼šåŸå§‹å†²åŠ¨å’Œæ¬²æœ›
    EGO = "ego"  # è‡ªæˆ‘ï¼šç°å®åŸåˆ™å’Œç†æ€§æ€è€ƒ
    SUPEREGO = "superego"  # è¶…æˆ‘ï¼šé“å¾·è‰¯çŸ¥å’Œç¤¾ä¼šè§„èŒƒ


class ConsciousnessCoherence(Enum):
    """æ„è¯†è¿è´¯æ€§ç­‰çº§ (Consciousness Coherence Levels)"""
    RANDOM = "random"  # éšæœºæ€§ï¼šç±»ä¼¼åšå°”å…¹æ›¼å¤§è„‘çš„éšæœºæ¶Œç°
    FRAGMENTED = "fragmented"  # ç¢ç‰‡åŒ–ï¼šéƒ¨åˆ†è¿è´¯ä½†æœ‰æ–­è£‚
    COHERENT = "coherent"  # è¿è´¯ï¼šç»“æ„åŒ–çš„æ„è¯†è¡¨è¾¾
    HYPERCOHERENT = "hypercoherent"  # è¶…è¿è´¯ï¼šè¿‡åº¦ç»“æ„åŒ–


@dataclass
class PsychodynamicProfile:
    """å¿ƒç†åŠ¨åŠ›å­¦æ¡£æ¡ˆ (Psychodynamic Profile)"""
    id_score: float = 0.0
    ego_score: float = 0.0
    superego_score: float = 0.0
    dominant_component: PsychodynamicComponent = PsychodynamicComponent.EGO
    consciousness_coherence: ConsciousnessCoherence = ConsciousnessCoherence.COHERENT
    randomness_entropy: float = 0.0
    emotional_intensity: float = 0.0


class BoltzmannBrainPsychoAnalyzer:
    """
    åšå°”å…¹æ›¼å¤§è„‘å¿ƒç†åˆ†æå™¨ (Boltzmann Brain Psychoanalytic Analyzer)
    
    Analyzes text for psychological constructs and consciousness patterns
    using Freudian psychology and Boltzmann brain theoretical frameworks.
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨ (Initialize analyzer)"""
        self._initialize_lexicons()
        self._initialize_nltk()
        
        # åšå°”å…¹æ›¼å¤§è„‘éšæœºæ€§é˜ˆå€¼ (Boltzmann brain randomness threshold)
        self.randomness_threshold = 0.7
        
        # æ„è¯†è¿è´¯æ€§å‚æ•° (Consciousness coherence parameters)
        self.coherence_window_size = 5
        self.semantic_coherence_threshold = 0.6
    
    def _initialize_lexicons(self):
        """åˆå§‹åŒ–å¿ƒç†åˆ†æè¯æ±‡åº“ (Initialize psychoanalytic lexicons)"""
        
        # æœ¬æˆ‘è¯æ±‡ (Id-related terms) - å†²åŠ¨ã€æ¬²æœ›ã€å³æ—¶æ»¡è¶³
        self.id_lexicon = {
            'english': [
                'want', 'need', 'desire', 'crave', 'hunger', 'thirst', 'lust', 'impulse',
                'immediate', 'now', 'must', 'urgent', 'pleasure', 'satisfaction', 'gratification',
                'instinct', 'drive', 'compulsion', 'addiction', 'obsession', 'passion',
                'rage', 'fury', 'angry', 'hate', 'love', 'sex', 'food', 'power',
                'mine', 'take', 'grab', 'seize', 'devour', 'consume', 'indulge'
            ],
            'chinese': [
                'æƒ³è¦', 'éœ€è¦', 'æ¸´æœ›', 'æ¬²æœ›', 'å†²åŠ¨', 'æœ¬èƒ½', 'ç«‹å³', 'é©¬ä¸Š', 'ç°åœ¨',
                'å¿…é¡»', 'å¿«æ„Ÿ', 'æ»¡è¶³', 'äº«å—', 'è´ªå©ª', 'æ„¤æ€’', 'ä»‡æ¨', 'çˆ±', 'æ€§',
                'é£Ÿç‰©', 'æƒåŠ›', 'æˆ‘çš„', 'æ‹¿', 'æŠ“', 'åå™¬', 'æ¶ˆè´¹', 'æ”¾çºµ',
                'é¥¥é¥¿', 'å¹²æ¸´', 'æ¿€æƒ…', 'ç‹‚æ€’', 'å æœ‰', 'æ§åˆ¶', 'å¾æœ'
            ]
        }
        
        # è‡ªæˆ‘è¯æ±‡ (Ego-related terms) - ç°å®ã€ç†æ€§ã€å¹³è¡¡
        self.ego_lexicon = {
            'english': [
                'think', 'consider', 'analyze', 'evaluate', 'rational', 'logical', 'reasonable',
                'balance', 'compromise', 'negotiate', 'plan', 'strategy', 'practical', 'realistic',
                'decide', 'choose', 'weigh', 'pros', 'cons', 'consequences', 'responsibility',
                'manage', 'organize', 'control', 'regulate', 'adapt', 'adjust', 'solve',
                'understand', 'comprehend', 'clarify', 'explain', 'justify', 'defense'
            ],
            'chinese': [
                'æ€è€ƒ', 'è€ƒè™‘', 'åˆ†æ', 'è¯„ä¼°', 'ç†æ€§', 'é€»è¾‘', 'åˆç†', 'å¹³è¡¡',
                'å¦¥å', 'åå•†', 'è®¡åˆ’', 'ç­–ç•¥', 'å®é™…', 'ç°å®', 'å†³å®š', 'é€‰æ‹©',
                'æƒè¡¡', 'åæœ', 'è´£ä»»', 'ç®¡ç†', 'ç»„ç»‡', 'æ§åˆ¶', 'è°ƒèŠ‚', 'é€‚åº”',
                'è°ƒæ•´', 'è§£å†³', 'ç†è§£', 'é¢†æ‚Ÿ', 'æ¾„æ¸…', 'è§£é‡Š', 'è¯æ˜', 'é˜²å¾¡'
            ]
        }
        
        # è¶…æˆ‘è¯æ±‡ (Superego-related terms) - é“å¾·ã€è§„èŒƒã€ç†æƒ³
        self.superego_lexicon = {
            'english': [
                'should', 'ought', 'must', 'moral', 'ethical', 'right', 'wrong', 'good', 'bad',
                'virtue', 'sin', 'guilt', 'shame', 'conscience', 'duty', 'obligation', 'principle',
                'ideal', 'perfect', 'pure', 'noble', 'honor', 'dignity', 'respect', 'proper',
                'appropriate', 'correct', 'decent', 'civilized', 'cultured', 'refined',
                'judge', 'criticize', 'condemn', 'approve', 'disapprove', 'praise', 'blame'
            ],
            'chinese': [
                'åº”è¯¥', 'å¿…é¡»', 'é“å¾·', 'ä¼¦ç†', 'å¯¹', 'é”™', 'å¥½', 'å', 'ç¾å¾·',
                'ç½ªæ¶', 'å†…ç–š', 'ç¾è€»', 'è‰¯å¿ƒ', 'ä¹‰åŠ¡', 'è´£ä»»', 'åŸåˆ™', 'ç†æƒ³',
                'å®Œç¾', 'çº¯æ´', 'é«˜å°š', 'è£èª‰', 'å°Šä¸¥', 'å°Šé‡', 'é€‚å½“', 'æ­£ç¡®',
                'ä½“é¢', 'æ–‡æ˜', 'æœ‰æ•™å…»', 'ç²¾è‡´', 'åˆ¤æ–­', 'æ‰¹è¯„', 'è°´è´£',
                'èµæˆ', 'åå¯¹', 'è¡¨æ‰¬', 'è´£å¤‡', 'è§„èŒƒ', 'æ ‡å‡†', 'å“å¾·'
            ]
        }
        
        # æ„è¯†è¿è´¯æ€§æŒ‡æ ‡è¯æ±‡ (Consciousness coherence indicators)
        self.coherence_markers = {
            'high_coherence': ['therefore', 'consequently', 'because', 'since', 'thus', 'hence',
                              'å› æ­¤', 'æ‰€ä»¥', 'å› ä¸º', 'ç”±äº', 'å› è€Œ', 'æ•…æ­¤'],
            'low_coherence': ['suddenly', 'randomly', 'somehow', 'anyway', 'whatever', 'strange',
                             'çªç„¶', 'éšæœº', 'è«åå…¶å¦™', 'ä¸çŸ¥æ€ä¹ˆ', 'åæ­£', 'å¥‡æ€ª']
        }
    
    def _initialize_nltk(self):
        """åˆå§‹åŒ–NLTKèµ„æº (Initialize NLTK resources)"""
        if NLTK_AVAILABLE:
            try:
                # Download required NLTK data if not already present
                nltk.data.find('tokenizers/punkt')
                nltk.data.find('corpora/wordnet')
                nltk.data.find('vader_lexicon')
            except LookupError:
                try:
                    nltk.download('punkt', quiet=True)
                    nltk.download('wordnet', quiet=True)
                    nltk.download('vader_lexicon', quiet=True)
                except Exception:
                    pass  # Handle download failures gracefully
            
            try:
                self.sentiment_analyzer = SentimentIntensityAnalyzer()
            except Exception:
                self.sentiment_analyzer = None
        else:
            self.sentiment_analyzer = None
    
    def analyze_psychodynamics(self, text: str, context: Optional[ExpressionContext] = None) -> PsychodynamicProfile:
        """
        åˆ†ææ–‡æœ¬çš„å¿ƒç†åŠ¨åŠ›å­¦ç‰¹å¾ (Analyze psychodynamic characteristics of text)
        
        Args:
            text: è¦åˆ†æçš„æ–‡æœ¬ (Text to analyze)
            context: è¡¨è¾¾è¯­å¢ƒ (Expression context)
        
        Returns:
            PsychodynamicProfile: å¿ƒç†åŠ¨åŠ›å­¦æ¡£æ¡ˆ (Psychodynamic profile)
        """
        if context is None:
            context = ExpressionContext()
        
        # è®¡ç®—ä¸‰ä¸ªå¿ƒç†ç»„ä»¶çš„åˆ†æ•° (Calculate scores for three psychic components)
        id_score = self._calculate_id_score(text)
        ego_score = self._calculate_ego_score(text)
        superego_score = self._calculate_superego_score(text)
        
        # ç¡®å®šä¸»å¯¼ç»„ä»¶ (Determine dominant component)
        scores = {'id': id_score, 'ego': ego_score, 'superego': superego_score}
        dominant_component = PsychodynamicComponent(max(scores, key=scores.get))
        
        # è®¡ç®—æ„è¯†è¿è´¯æ€§ (Calculate consciousness coherence)
        consciousness_coherence = self._analyze_consciousness_coherence(text)
        
        # è®¡ç®—åšå°”å…¹æ›¼å¤§è„‘éšæœºæ€§ç†µ (Calculate Boltzmann brain randomness entropy)
        randomness_entropy = self._calculate_randomness_entropy(text)
        
        # è®¡ç®—æƒ…æ„Ÿå¼ºåº¦ (Calculate emotional intensity)
        emotional_intensity = self._calculate_emotional_intensity(text)
        
        return PsychodynamicProfile(
            id_score=id_score,
            ego_score=ego_score,
            superego_score=superego_score,
            dominant_component=dominant_component,
            consciousness_coherence=consciousness_coherence,
            randomness_entropy=randomness_entropy,
            emotional_intensity=emotional_intensity
        )
    
    def _calculate_id_score(self, text: str) -> float:
        """è®¡ç®—æœ¬æˆ‘åˆ†æ•° (Calculate Id score)"""
        return self._calculate_lexicon_score(text, self.id_lexicon)
    
    def _calculate_ego_score(self, text: str) -> float:
        """è®¡ç®—è‡ªæˆ‘åˆ†æ•° (Calculate Ego score)"""
        return self._calculate_lexicon_score(text, self.ego_lexicon)
    
    def _calculate_superego_score(self, text: str) -> float:
        """è®¡ç®—è¶…æˆ‘åˆ†æ•° (Calculate Superego score)"""
        return self._calculate_lexicon_score(text, self.superego_lexicon)
    
    def _calculate_lexicon_score(self, text: str, lexicon: Dict[str, List[str]]) -> float:
        """æ ¹æ®è¯æ±‡åº“è®¡ç®—åˆ†æ•° (Calculate score based on lexicon)"""
        text_lower = text.lower()
        
        # æ£€æµ‹è¯­è¨€ (Detect language)
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
        
        if chinese_chars > english_words:
            relevant_lexicon = lexicon.get('chinese', [])
        else:
            relevant_lexicon = lexicon.get('english', [])
        
        if not relevant_lexicon:
            return 0.0
        
        # è®¡ç®—åŒ¹é…çš„è¯æ±‡æ•°é‡ (Count matching terms)
        matches = 0
        total_words = len(text_lower.split())
        
        for term in relevant_lexicon:
            matches += text_lower.count(term.lower())
        
        if total_words == 0:
            return 0.0
        
        # å½’ä¸€åŒ–åˆ†æ•° (Normalize score)
        score = min(matches / total_words, 1.0)
        return score
    
    def _analyze_consciousness_coherence(self, text: str) -> ConsciousnessCoherence:
        """
        åˆ†ææ„è¯†è¿è´¯æ€§ (Analyze consciousness coherence)
        
        Uses Boltzmann brain theory: random consciousness vs structured thought
        """
        if not text.strip():
            return ConsciousnessCoherence.FRAGMENTED
        
        # è®¡ç®—è¯­ä¹‰è¿è´¯æ€§æŒ‡æ ‡ (Calculate semantic coherence indicators)
        coherence_score = 0.0
        
        # 1. é€»è¾‘è¿æ¥è¯å¯†åº¦ (Logical connector density)
        high_coherence_markers = self.coherence_markers['high_coherence']
        low_coherence_markers = self.coherence_markers['low_coherence']
        
        text_lower = text.lower()
        high_markers = sum(text_lower.count(marker) for marker in high_coherence_markers)
        low_markers = sum(text_lower.count(marker) for marker in low_coherence_markers)
        
        total_words = len(text_lower.split())
        if total_words > 0:
            coherence_score += (high_markers - low_markers) / total_words
        
        # 2. å¥å­é•¿åº¦å˜å¼‚æ€§ (Sentence length variability)
        if NLTK_AVAILABLE:
            try:
                sentences = sent_tokenize(text)
                if len(sentences) > 1:
                    lengths = [len(s.split()) for s in sentences]
                    if NUMPY_AVAILABLE:
                        variability = np.std(lengths) / (np.mean(lengths) + 1e-10)
                    else:
                        mean_len = sum(lengths) / len(lengths)
                        variance = sum((x - mean_len) ** 2 for x in lengths) / len(lengths)
                        variability = (variance ** 0.5) / (mean_len + 1e-10)
                    
                    # é«˜å˜å¼‚æ€§è¡¨ç¤ºä½è¿è´¯æ€§ (High variability indicates low coherence)
                    coherence_score -= variability * 0.1
            except Exception:
                pass
        
        # 3. é‡å¤æ¨¡å¼ (Repetition patterns)
        words = text_lower.split()
        if len(words) > 3:
            word_freq = Counter(words)
            repetition_ratio = sum(1 for count in word_freq.values() if count > 1) / len(word_freq)
            
            # é€‚åº¦é‡å¤è¡¨ç¤ºè¿è´¯æ€§ (Moderate repetition indicates coherence)
            if 0.1 <= repetition_ratio <= 0.4:
                coherence_score += 0.1
            elif repetition_ratio > 0.6:  # è¿‡åº¦é‡å¤å¯èƒ½è¡¨ç¤ºæ„è¯†éšœç¢
                coherence_score -= 0.2
        
        # åˆ†ç±»è¿è´¯æ€§ç­‰çº§ (Classify coherence level)
        if coherence_score > 0.3:
            return ConsciousnessCoherence.HYPERCOHERENT
        elif coherence_score > 0.1:
            return ConsciousnessCoherence.COHERENT
        elif coherence_score > -0.1:
            return ConsciousnessCoherence.FRAGMENTED
        else:
            return ConsciousnessCoherence.RANDOM
    
    def _calculate_randomness_entropy(self, text: str) -> float:
        """
        è®¡ç®—éšæœºæ€§ç†µ (Calculate randomness entropy)
        
        Inspired by Boltzmann brain theory - measures how random the text appears
        versus having structured consciousness behind it.
        """
        if not text.strip():
            return 1.0
        
        # å­—ç¬¦çº§ç†µ (Character-level entropy)
        char_freq = Counter(text.lower())
        total_chars = len(text)
        char_entropy = 0.0
        
        for count in char_freq.values():
            prob = count / total_chars
            if prob > 0:
                char_entropy -= prob * math.log2(prob)
        
        # å½’ä¸€åŒ–åˆ° [0, 1] (Normalize to [0, 1])
        max_entropy = math.log2(len(char_freq)) if len(char_freq) > 0 else 1.0
        normalized_entropy = char_entropy / max_entropy if max_entropy > 0 else 0.0
        
        # è¯æ±‡çº§æ¨¡å¼åˆ†æ (Word-level pattern analysis)
        words = text.lower().split()
        if len(words) > 1:
            # è®¡ç®—ç›¸é‚»è¯çš„è¯­ä¹‰ç›¸å…³æ€§ (Calculate semantic relatedness of adjacent words)
            semantic_breaks = 0
            for i in range(len(words) - 1):
                # ç®€å•çš„è¯­ä¹‰æ–­è£‚æ£€æµ‹ (Simple semantic break detection)
                current_word = words[i]
                next_word = words[i + 1]
                
                # æ£€æŸ¥è¯æ€§ç±»åˆ«çªå˜ (Check for part-of-speech category jumps)
                if self._are_semantically_unrelated(current_word, next_word):
                    semantic_breaks += 1
            
            semantic_randomness = semantic_breaks / (len(words) - 1)
        else:
            semantic_randomness = 0.0
        
        # ç»„åˆå­—ç¬¦ç†µå’Œè¯­ä¹‰éšæœºæ€§ (Combine character entropy and semantic randomness)
        overall_randomness = (normalized_entropy + semantic_randomness) / 2
        return min(overall_randomness, 1.0)
    
    def _are_semantically_unrelated(self, word1: str, word2: str) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªè¯æ˜¯å¦è¯­ä¹‰æ— å…³ (Check if two words are semantically unrelated)"""
        # ç®€åŒ–çš„è¯­ä¹‰ç›¸å…³æ€§æ£€æµ‹ (Simplified semantic relatedness detection)
        
        # åŠŸèƒ½è¯å’Œå†…å®¹è¯çš„åŸºæœ¬åˆ†ç±» (Basic classification of function vs content words)
        function_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
                         'of', 'with', 'by', 'from', 'is', 'are', 'was', 'were', 'be', 'been',
                         'çš„', 'åœ¨', 'å’Œ', 'æˆ–', 'ä½†æ˜¯', 'å› ä¸º', 'æ‰€ä»¥', 'æ˜¯', 'äº†', 'ç€', 'è¿‡'}
        
        # å¦‚æœéƒ½æ˜¯åŠŸèƒ½è¯ï¼Œè®¤ä¸ºç›¸å…³ (If both are function words, consider related)
        if word1 in function_words and word2 in function_words:
            return False
        
        # å¦‚æœä¸€ä¸ªæ˜¯åŠŸèƒ½è¯ä¸€ä¸ªä¸æ˜¯ï¼Œè®¤ä¸ºæ­£å¸¸ (If one is function word and one isn't, normal)
        if (word1 in function_words) != (word2 in function_words):
            return False
        
        # ç®€å•çš„å­—ç¬¦ç›¸ä¼¼æ€§æ£€æµ‹ (Simple character similarity detection)
        common_chars = set(word1) & set(word2)
        if len(common_chars) >= min(len(word1), len(word2)) * 0.5:
            return False
        
        # å¦‚æœè¯é•¿åº¦å·®å¼‚è¿‡å¤§ï¼Œå¯èƒ½è¯­ä¹‰æ— å…³ (If word length differs too much, might be unrelated)
        if abs(len(word1) - len(word2)) > max(len(word1), len(word2)) * 0.7:
            return True
        
        return False
    
    def _calculate_emotional_intensity(self, text: str) -> float:
        """è®¡ç®—æƒ…æ„Ÿå¼ºåº¦ (Calculate emotional intensity)"""
        if self.sentiment_analyzer and NLTK_AVAILABLE:
            try:
                scores = self.sentiment_analyzer.polarity_scores(text)
                # ä½¿ç”¨å¤åˆåˆ†æ•°çš„ç»å¯¹å€¼ä½œä¸ºæƒ…æ„Ÿå¼ºåº¦ (Use absolute compound score as intensity)
                return abs(scores['compound'])
            except Exception:
                pass
        
        # é™çº§æ–¹æ³•ï¼šåŸºäºæƒ…æ„Ÿè¯æ±‡ (Fallback: emotion word-based method)
        emotion_words = [
            'love', 'hate', 'angry', 'happy', 'sad', 'excited', 'furious', 'delighted',
            'disgusted', 'afraid', 'surprised', 'ashamed', 'guilty', 'proud',
            'çˆ±', 'æ¨', 'æ„¤æ€’', 'é«˜å…´', 'æ‚²ä¼¤', 'å…´å¥‹', 'ç‹‚æ€’', 'é«˜å…´',
            'åŒæ¶', 'å®³æ€•', 'æƒŠè®¶', 'ç¾æ„§', 'å†…ç–š', 'éª„å‚²', 'æ¿€åŠ¨', 'ç—›è‹¦'
        ]
        
        text_lower = text.lower()
        emotion_count = sum(text_lower.count(word) for word in emotion_words)
        total_words = len(text_lower.split())
        
        if total_words == 0:
            return 0.0
        
        return min(emotion_count / total_words * 2, 1.0)  # ä¹˜ä»¥2å¢å¼ºå¼ºåº¦
    
    def generate_boltzmann_profile_report(self, profile: PsychodynamicProfile, 
                                        text: str = "", detailed: bool = True) -> str:
        """
        ç”Ÿæˆåšå°”å…¹æ›¼å¤§è„‘å¿ƒç†æ¡£æ¡ˆæŠ¥å‘Š (Generate Boltzmann brain psycho profile report)
        
        Args:
            profile: å¿ƒç†åŠ¨åŠ›å­¦æ¡£æ¡ˆ (Psychodynamic profile)
            text: åŸå§‹æ–‡æœ¬ (Original text)
            detailed: æ˜¯å¦ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š (Whether to generate detailed report)
        
        Returns:
            str: æ ¼å¼åŒ–çš„åˆ†ææŠ¥å‘Š (Formatted analysis report)
        """
        report = []
        report.append("=" * 60)
        report.append("åšå°”å…¹æ›¼å¤§è„‘å¿ƒç†åˆ†ææŠ¥å‘Š (Boltzmann Brain Psychoanalytic Report)")
        report.append("=" * 60)
        
        if text:
            report.append(f"\nåŸå§‹æ–‡æœ¬ (Original Text): {text[:100]}{'...' if len(text) > 100 else ''}")
        
        report.append("\nğŸ“Š å¿ƒç†ç»“æ„åˆ†æ (Psychic Structure Analysis)")
        report.append("-" * 40)
        report.append(f"æœ¬æˆ‘ (Id) åˆ†æ•°: {profile.id_score:.3f}")
        report.append(f"è‡ªæˆ‘ (Ego) åˆ†æ•°: {profile.ego_score:.3f}")
        report.append(f"è¶…æˆ‘ (Superego) åˆ†æ•°: {profile.superego_score:.3f}")
        report.append(f"ä¸»å¯¼ç»„ä»¶ (Dominant Component): {profile.dominant_component.value.upper()}")
        
        # å¿ƒç†ç»“æ„è§£é‡Š (Psychic structure interpretation)
        if profile.dominant_component == PsychodynamicComponent.ID:
            interpretation = "æœ¬æˆ‘ä¸»å¯¼ - è¡¨è¾¾ä½“ç°åŸå§‹å†²åŠ¨å’Œå³æ—¶æ¬²æœ› (Id-dominant: expression reflects primitive impulses and immediate desires)"
        elif profile.dominant_component == PsychodynamicComponent.EGO:
            interpretation = "è‡ªæˆ‘ä¸»å¯¼ - è¡¨è¾¾ä½“ç°ç†æ€§æ€è€ƒå’Œç°å®åŸåˆ™ (Ego-dominant: expression reflects rational thinking and reality principle)"
        else:
            interpretation = "è¶…æˆ‘ä¸»å¯¼ - è¡¨è¾¾ä½“ç°é“å¾·æ ‡å‡†å’Œç¤¾ä¼šè§„èŒƒ (Superego-dominant: expression reflects moral standards and social norms)"
        
        report.append(f"è§£é‡Š (Interpretation): {interpretation}")
        
        report.append("\nğŸ§  æ„è¯†è¿è´¯æ€§åˆ†æ (Consciousness Coherence Analysis)")
        report.append("-" * 40)
        report.append(f"è¿è´¯æ€§ç­‰çº§ (Coherence Level): {profile.consciousness_coherence.value.upper()}")
        report.append(f"éšæœºæ€§ç†µ (Randomness Entropy): {profile.randomness_entropy:.3f}")
        
        # åšå°”å…¹æ›¼å¤§è„‘è§£é‡Š (Boltzmann brain interpretation)
        if profile.consciousness_coherence == ConsciousnessCoherence.RANDOM:
            boltzmann_interpretation = "ç±»ä¼¼åšå°”å…¹æ›¼å¤§è„‘çš„éšæœºæ„è¯†æ¶Œç° (Similar to Boltzmann brain random consciousness emergence)"
        elif profile.consciousness_coherence == ConsciousnessCoherence.FRAGMENTED:
            boltzmann_interpretation = "éƒ¨åˆ†è¿è´¯ä½†å­˜åœ¨æ„è¯†æ–­è£‚ (Partially coherent but with consciousness breaks)"
        elif profile.consciousness_coherence == ConsciousnessCoherence.COHERENT:
            boltzmann_interpretation = "ç»“æ„åŒ–çš„æ„è¯†è¡¨è¾¾ (Structured consciousness expression)"
        else:
            boltzmann_interpretation = "è¿‡åº¦ç»“æ„åŒ–å¯èƒ½è¡¨ç¤ºå¼ºè¿«æ€§æ€ç»´ (Over-structuring may indicate compulsive thinking)"
        
        report.append(f"åšå°”å…¹æ›¼è§£é‡Š (Boltzmann Interpretation): {boltzmann_interpretation}")
        
        report.append(f"\nğŸ’« æƒ…æ„Ÿå¼ºåº¦ (Emotional Intensity): {profile.emotional_intensity:.3f}")
        
        if detailed and (profile.randomness_entropy > 0.7 or 
                        profile.consciousness_coherence == ConsciousnessCoherence.RANDOM):
            report.append("\nâš ï¸  åšå°”å…¹æ›¼å¤§è„‘è­¦æŠ¥ (Boltzmann Brain Alert)")
            report.append("-" * 40)
            report.append("é«˜éšæœºæ€§ç†µæ£€æµ‹åˆ°å¯èƒ½çš„:")
            report.append("â€¢ æ„è¯†æµå¼è¡¨è¾¾ (Stream-of-consciousness expression)")
            report.append("â€¢ éšæœºè”æƒ³æ¨¡å¼ (Random association patterns)")
            report.append("â€¢ å¯èƒ½çš„æ„è¯†çŠ¶æ€æ”¹å˜ (Possible altered consciousness state)")
        
        if detailed:
            report.append("\nğŸ“ˆ è¯¦ç»†åˆ†æå»ºè®® (Detailed Analysis Recommendations)")
            report.append("-" * 40)
            
            if profile.id_score > 0.3:
                report.append("â€¢ é«˜æœ¬æˆ‘æ´»åŠ¨ï¼šå»ºè®®å…³æ³¨å†²åŠ¨æ§åˆ¶å’Œæƒ…ç»ªè°ƒèŠ‚")
            if profile.superego_score > 0.3:
                report.append("â€¢ é«˜è¶…æˆ‘æ´»åŠ¨ï¼šå»ºè®®å…³æ³¨å¿ƒç†å‹åŠ›å’Œå®Œç¾ä¸»ä¹‰å€¾å‘")
            if profile.consciousness_coherence == ConsciousnessCoherence.FRAGMENTED:
                report.append("â€¢ æ„è¯†ç¢ç‰‡åŒ–ï¼šå»ºè®®å…³æ³¨æ³¨æ„åŠ›å’Œæ€ç»´ç»„ç»‡èƒ½åŠ›")
        
        report.append("\n" + "=" * 60)
        
        return "\n".join(report)
    
    def comprehensive_evaluation(self, text: str, 
                               context: Optional[ExpressionContext] = None) -> EvaluationResult:
        """
        ç»¼åˆè¯„ä¼° (Comprehensive evaluation)
        
        Returns evaluation result compatible with HumanExpressionEvaluator framework
        """
        profile = self.analyze_psychodynamics(text, context)
        
        # è®¡ç®—ç»¼åˆåˆ†æ•° (Calculate comprehensive score)
        # å¹³è¡¡å¿ƒç†å¥åº·æŒ‡æ ‡ (Balance psychological health indicators)
        balance_score = 1.0 - abs(profile.id_score - profile.ego_score) - abs(profile.ego_score - profile.superego_score)
        coherence_score = 1.0 if profile.consciousness_coherence == ConsciousnessCoherence.COHERENT else 0.5
        randomness_score = 1.0 - profile.randomness_entropy
        
        overall_score = (balance_score + coherence_score + randomness_score) / 3
        overall_score = max(0.0, min(1.0, overall_score))  # é™åˆ¶åœ¨ [0, 1]
        
        # è®¡ç®—ä¿¡å¿ƒåº¦ (Calculate confidence)
        confidence = 0.8 if text and len(text.split()) > 5 else 0.5
        
        explanation = f"å¿ƒç†å¹³è¡¡: {balance_score:.2f}, æ„è¯†è¿è´¯: {coherence_score:.2f}, éšæœºæ€§æ§åˆ¶: {randomness_score:.2f}"
        
        return EvaluationResult(
            dimension=EvaluationDimension.PSYCHOLOGICAL if HUMAN_EVALUATOR_AVAILABLE 
                      else EvaluationDimension.BOLTZMANN,
            score=overall_score,
            confidence=confidence,
            explanation=explanation,
            sub_scores={
                'psychic_balance': balance_score,
                'consciousness_coherence': coherence_score,
                'randomness_control': randomness_score,
                'id_score': profile.id_score,
                'ego_score': profile.ego_score,
                'superego_score': profile.superego_score,
                'randomness_entropy': profile.randomness_entropy,
                'emotional_intensity': profile.emotional_intensity
            }
        )


# ä½¿ç”¨ç¤ºä¾‹ (Usage Example)
if __name__ == "__main__":
    analyzer = BoltzmannBrainPsychoAnalyzer()
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„æ–‡æœ¬ (Test different types of text)
    test_texts = [
        "I want it now! Give me everything I desire immediately!",
        "æˆ‘éœ€è¦ä»”ç»†è€ƒè™‘è¿™ä¸ªå†³å®šçš„æ‰€æœ‰åæœï¼Œæƒè¡¡åˆ©å¼Šã€‚",
        "We should always do what is morally right and proper in society.",
        "purple elephant dancing quantum mechanics randomly fluctuating consciousness emerging from void suddenly meaningful patterns dissolve into chaos beautiful symmetry",
        "æˆ‘åº”è¯¥æ›´åŠ åŠªåŠ›å·¥ä½œï¼Œåšä¸€ä¸ªæœ‰é“å¾·çš„å¥½äººï¼Œä¸èƒ½è®©çˆ¶æ¯å¤±æœ›ã€‚"
    ]
    
    print("åšå°”å…¹æ›¼å¤§è„‘å¿ƒç†åˆ†æå™¨æµ‹è¯• (Boltzmann Brain Psychoanalyzer Test)")
    print("=" * 70)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\næµ‹è¯• {i} (Test {i}):")
        profile = analyzer.analyze_psychodynamics(text)
        report = analyzer.generate_boltzmann_profile_report(profile, text, detailed=False)
        print(report)
        
        # è·å–è¯„ä¼°ç»“æœ (Get evaluation result)
        evaluation = analyzer.comprehensive_evaluation(text)
        print(f"\nç»¼åˆè¯„ä¼°åˆ†æ•° (Comprehensive Score): {evaluation.score:.3f}")
        print(f"ä¿¡å¿ƒåº¦ (Confidence): {evaluation.confidence:.3f}")
        print("-" * 70)