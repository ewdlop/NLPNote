#!/usr/bin/env python3
"""
Neural Missing Firing Detection Example
ç¥ç¶“å…ƒç¼ºå¤±æ¿€ç™¼æª¢æ¸¬ç¤ºä¾‹

This script demonstrates how to detect and analyze neural missing firing
patterns in LLMs using the neural firing analysis framework.

è©²è…³æœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç¥ç¶“æ¿€ç™¼åˆ†ææ¡†æ¶æª¢æ¸¬å’Œåˆ†æLLMä¸­çš„ç¥ç¶“å…ƒç¼ºå¤±æ¿€ç™¼æ¨¡å¼ã€‚
"""

import sys
import numpy as np
from typing import List, Dict, Any

try:
    from NeuralFiringAnalyzer import NeuralFiringAnalyzer, FiringPatternType
    from SubtextAnalyzer import SubtextAnalyzer
    from HumanExpressionEvaluator import HumanExpressionEvaluator, ExpressionContext
    MODULES_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Some modules not available: {e}")
    MODULES_AVAILABLE = False
    sys.exit(1)


class NeuralFiringDemonstrator:
    """
    Demonstrates neural firing detection capabilities
    æ¼”ç¤ºç¥ç¶“æ¿€ç™¼æª¢æ¸¬åŠŸèƒ½
    """
    
    def __init__(self):
        if not MODULES_AVAILABLE:
            raise ImportError("Required modules not available")
        
        self.neural_analyzer = NeuralFiringAnalyzer()
        self.text_analyzer = SubtextAnalyzer()
        self.expression_evaluator = HumanExpressionEvaluator()
    
    def demo_basic_firing_analysis(self):
        """Demonstrate basic neural firing analysis"""
        print("=" * 60)
        print("åŸºæœ¬ç¥ç¶“æ¿€ç™¼åˆ†ææ¼”ç¤º (Basic Neural Firing Analysis Demo)")
        print("=" * 60)
        
        # Analyze a healthy network
        print("\n1. åˆ†æå¥åº·ç¶²è·¯ (Analyzing Healthy Network):")
        healthy_report = self.neural_analyzer.analyze_simulated_llm_activations(
            num_layers=8,
            hidden_size=512,
            sequence_length=128,
            simulate_issues=False
        )
        
        print(f"   å¥åº·åˆ†æ•¸ (Health Score): {healthy_report.overall_health_score:.3f}")
        print(f"   å•é¡Œå±¤æ•¸ (Problematic Layers): {healthy_report.problematic_layers}")
        print(f"   ç¼ºå¤±æ¿€ç™¼ç‡ (Missing Firing Rate): {healthy_report.missing_firing_percentage:.2f}%")
        
        # Analyze a problematic network
        print("\n2. åˆ†æå•é¡Œç¶²è·¯ (Analyzing Problematic Network):")
        problematic_report = self.neural_analyzer.analyze_simulated_llm_activations(
            num_layers=8,
            hidden_size=512,
            sequence_length=128,
            simulate_issues=True
        )
        
        print(f"   å¥åº·åˆ†æ•¸ (Health Score): {problematic_report.overall_health_score:.3f}")
        print(f"   å•é¡Œå±¤æ•¸ (Problematic Layers): {problematic_report.problematic_layers}")
        print(f"   ç¼ºå¤±æ¿€ç™¼ç‡ (Missing Firing Rate): {problematic_report.missing_firing_percentage:.2f}%")
        
        # Show comparison
        print(f"\n3. æ¯”è¼ƒçµæœ (Comparison Results):")
        health_diff = healthy_report.overall_health_score - problematic_report.overall_health_score
        print(f"   å¥åº·åˆ†æ•¸å·®ç•° (Health Score Difference): {health_diff:.3f}")
        
        if health_diff > 0.2:
            print("   âš ï¸  æª¢æ¸¬åˆ°é¡¯è‘—çš„ç¥ç¶“æ¿€ç™¼å•é¡Œ (Significant neural firing issues detected)")
        else:
            print("   âœ… ç¥ç¶“æ¿€ç™¼æ¨¡å¼ç›¸å°æ­£å¸¸ (Neural firing patterns relatively normal)")
        
        return healthy_report, problematic_report
    
    def demo_layer_specific_analysis(self):
        """Demonstrate layer-by-layer analysis"""
        print("\n" + "=" * 60)
        print("åˆ†å±¤åˆ†ææ¼”ç¤º (Layer-by-Layer Analysis Demo)")
        print("=" * 60)
        
        # Create network with specific issues
        report = self.neural_analyzer.analyze_simulated_llm_activations(
            num_layers=6,
            simulate_issues=True
        )
        
        print("\nå±¤ç´šè©³ç´°åˆ†æ (Layer Detail Analysis):")
        print("-" * 40)
        
        for i, layer in enumerate(report.layer_analyses):
            status_emoji = "âŒ" if layer.issues else "âœ…"
            
            print(f"\n{status_emoji} ç¬¬ {i+1} å±¤ (Layer {i+1}): {layer.layer_name}")
            print(f"     æ¿€ç™¼ç‡ (Firing Rate): {layer.activation_rate:.3f}")
            print(f"     æ¿€ç™¼æ¨¡å¼ (Pattern): {layer.firing_pattern.value}")
            print(f"     æ­»äº¡ç¥ç¶“å…ƒ (Dead Neurons): {layer.dead_neurons}")
            
            if layer.issues:
                print(f"     å•é¡Œ (Issues):")
                for issue in layer.issues:
                    print(f"       - {issue}")
        
        return report
    
    def demo_text_processing_analysis(self):
        """Demonstrate neural firing analysis for text processing"""
        print("\n" + "=" * 60)
        print("æ–‡æœ¬è™•ç†ç¥ç¶“æ¿€ç™¼åˆ†ææ¼”ç¤º (Text Processing Neural Firing Analysis)")
        print("=" * 60)
        
        test_texts = [
            {
                'text': "Hello world!",
                'description': "ç°¡å–®æ–‡æœ¬ (Simple text)"
            },
            {
                'text': "The quick brown fox jumps over the lazy dog, demonstrating various linguistic patterns.",
                'description': "ä¸­ç­‰è¤‡é›œæ–‡æœ¬ (Medium complexity text)"
            },
            {
                'text': "In the realm of artificial intelligence, neural networks exhibit complex activation patterns that may sometimes fail to fire properly, leading to degraded performance in natural language processing tasks, which requires sophisticated monitoring and diagnostic tools to detect and remediate such issues.",
                'description': "è¤‡é›œæ–‡æœ¬ (Complex text)"
            },
            {
                'text': "ç¥ç¶“ç¶²è·¯åœ¨è™•ç†è‡ªç„¶èªè¨€æ™‚å¯èƒ½æœƒå‡ºç¾æ¿€ç™¼æ¨¡å¼ç•°å¸¸ï¼Œé€™æœƒå½±éŸ¿èªè¨€æ¨¡å‹çš„æ€§èƒ½ã€‚",
                'description': "ä¸­æ–‡æ–‡æœ¬ (Chinese text)"
            }
        ]
        
        print("\næ–‡æœ¬ç¥ç¶“æ¿€ç™¼åˆ†æçµæœ (Text Neural Firing Analysis Results):")
        print("-" * 50)
        
        for i, test_case in enumerate(test_texts, 1):
            print(f"\n{i}. {test_case['description']}")
            print(f"   æ–‡æœ¬ (Text): \"{test_case['text'][:50]}{'...' if len(test_case['text']) > 50 else ''}\"")
            
            try:
                result = self.text_analyzer.analyze_expression_evaluation(test_case['text'])
                
                if 'neural_firing_analysis' in result:
                    nfa = result['neural_firing_analysis']
                    print(f"   ç¥ç¶“å¥åº·åˆ†æ•¸ (Neural Health): {nfa['neural_health_score']:.3f}")
                    print(f"   æ¿€ç™¼ç‡ (Firing Rate): {nfa['overall_firing_rate']:.3f}")
                    print(f"   å•é¡Œæ•¸é‡ (Issues): {nfa['total_issues']}")
                    
                    # Add interpretation based on scores
                    if nfa['neural_health_score'] > 0.8:
                        status = "âœ… è‰¯å¥½ (Good)"
                    elif nfa['neural_health_score'] > 0.6:
                        status = "âš ï¸ ä¸€èˆ¬ (Fair)"
                    else:
                        status = "âŒ è¼ƒå·® (Poor)"
                    
                    print(f"   ç‹€æ…‹ (Status): {status}")
                else:
                    print(f"   âŒ ç¥ç¶“æ¿€ç™¼åˆ†æä¸å¯ç”¨ (Neural firing analysis unavailable)")
                    
            except Exception as e:
                print(f"   âŒ åˆ†æéŒ¯èª¤ (Analysis error): {e}")
    
    def demo_issue_detection(self):
        """Demonstrate specific issue detection"""
        print("\n" + "=" * 60)
        print("ç‰¹å®šå•é¡Œæª¢æ¸¬æ¼”ç¤º (Specific Issue Detection Demo)")
        print("=" * 60)
        
        # Create different types of problematic activations
        issue_types = {
            'missing_firing': {
                'description': 'ç¼ºå¤±æ¿€ç™¼ (Missing Firing)',
                'activation': np.random.normal(0, 0.01, (100, 100))  # Very low activations
            },
            'dead_neurons': {
                'description': 'æ­»äº¡ç¥ç¶“å…ƒ (Dead Neurons)',
                'activation': np.zeros((100, 100))  # All zeros
            },
            'saturated_neurons': {
                'description': 'é£½å’Œç¥ç¶“å…ƒ (Saturated Neurons)',
                'activation': np.ones((100, 100)) * 10  # All very high values
            },
            'sporadic_firing': {
                'description': 'é›¶æ˜Ÿæ¿€ç™¼ (Sporadic Firing)',
                'activation': np.random.choice([0, 10], size=(100, 100), p=[0.95, 0.05])
            }
        }
        
        print("\nå•é¡Œé¡å‹æª¢æ¸¬çµæœ (Issue Type Detection Results):")
        print("-" * 45)
        
        for issue_type, config in issue_types.items():
            print(f"\nğŸ” {config['description']}")
            
            # Apply activation function
            activation = np.tanh(config['activation'])
            
            # Analyze the activation pattern
            analysis = self.neural_analyzer.analyze_activation_tensor(
                activation, 
                f"test_layer_{issue_type}"
            )
            
            print(f"   æ¿€ç™¼ç‡ (Firing Rate): {analysis.activation_rate:.3f}")
            print(f"   æ¿€ç™¼æ¨¡å¼ (Pattern): {analysis.firing_pattern.value}")
            print(f"   æ­»äº¡ç¥ç¶“å…ƒ (Dead Neurons): {analysis.dead_neurons}")
            print(f"   å•é¡Œæ•¸é‡ (Issues): {len(analysis.issues)}")
            
            if analysis.issues:
                print(f"   æª¢æ¸¬åˆ°çš„å•é¡Œ (Detected Issues):")
                for issue in analysis.issues[:2]:  # Show first 2 issues
                    print(f"     - {issue}")
                if len(analysis.issues) > 2:
                    print(f"     ... é‚„æœ‰ {len(analysis.issues) - 2} å€‹å•é¡Œ (and {len(analysis.issues) - 2} more)")
    
    def demo_comprehensive_analysis(self):
        """Demonstrate comprehensive analysis combining all features"""
        print("\n" + "=" * 60)
        print("ç¶œåˆåˆ†ææ¼”ç¤º (Comprehensive Analysis Demo)")
        print("=" * 60)
        
        # Sample text for comprehensive analysis
        sample_text = "Large language models require careful monitoring of neural activation patterns to ensure optimal performance and prevent degradation due to missing firing or other neural issues."
        
        print(f"\nåˆ†ææ–‡æœ¬ (Analyzing Text):")
        print(f"\"{sample_text}\"")
        
        # 1. Expression evaluation
        print(f"\n1. è¡¨é”è©•ä¼° (Expression Evaluation):")
        context = ExpressionContext(
            situation='technical',
            formality_level='formal'
        )
        
        expr_result = self.expression_evaluator.comprehensive_evaluation(sample_text, context)
        print(f"   æ•´é«”åˆ†æ•¸ (Overall Score): {expr_result['integrated']['overall_score']:.3f}")
        print(f"   ä¿¡å¿ƒåº¦ (Confidence): {expr_result['integrated']['overall_confidence']:.3f}")
        
        # 2. Subtext analysis
        print(f"\n2. æ½›æ–‡æœ¬åˆ†æ (Subtext Analysis):")
        subtext_result = self.text_analyzer.calculate_subtext_probability(sample_text)
        print(f"   æ½›æ–‡æœ¬æ¦‚ç‡ (Subtext Probability): {subtext_result['probability']:.3f}")
        print(f"   è±¡å¾µæ€§ (Symbolism): {subtext_result['components']['symbolism']:.3f}")
        print(f"   æƒ…æ„Ÿæ·±åº¦ (Emotion Depth): {subtext_result['components']['emotion_depth']:.3f}")
        
        # 3. Neural firing analysis
        print(f"\n3. ç¥ç¶“æ¿€ç™¼åˆ†æ (Neural Firing Analysis):")
        integrated_result = self.text_analyzer.analyze_expression_evaluation(sample_text, context)
        
        if 'neural_firing_analysis' in integrated_result:
            nfa = integrated_result['neural_firing_analysis']
            print(f"   ç¥ç¶“å¥åº·åˆ†æ•¸ (Neural Health Score): {nfa['neural_health_score']:.3f}")
            print(f"   æ¿€ç™¼ç‡ (Firing Rate): {nfa['overall_firing_rate']:.3f}")
            print(f"   è™•ç†éšæ®µ (Processing Stages): {len(nfa['stage_analyses'])}")
            
            # Show stage-by-stage analysis
            print(f"\n   éšæ®µåˆ†æ (Stage Analysis):")
            for stage_info in nfa['stage_analyses']:
                stage = stage_info['stage']
                analysis = stage_info['analysis']
                emoji = "âœ…" if not analysis.issues else "âš ï¸" if len(analysis.issues) <= 2 else "âŒ"
                print(f"     {emoji} {stage}: æ¿€ç™¼ç‡ {analysis.activation_rate:.3f}, å•é¡Œ {len(analysis.issues)}")
        
        # 4. Integrated interpretation
        print(f"\n4. æ•´åˆè§£é‡‹ (Integrated Interpretation):")
        print(f"{integrated_result['interpretation']}")
        
        return integrated_result
    
    def demo_recommendations(self):
        """Demonstrate recommendation system"""
        print("\n" + "=" * 60)
        print("å»ºè­°ç³»çµ±æ¼”ç¤º (Recommendation System Demo)")
        print("=" * 60)
        
        # Create a problematic network scenario
        report = self.neural_analyzer.analyze_simulated_llm_activations(
            num_layers=10,
            simulate_issues=True
        )
        
        print(f"\nç¶²è·¯ç‹€æ…‹ (Network Status):")
        print(f"å¥åº·åˆ†æ•¸ (Health Score): {report.overall_health_score:.3f}")
        print(f"å•é¡Œå±¤æ•¸ (Problematic Layers): {report.problematic_layers}/{report.total_layers}")
        
        print(f"\nç³»çµ±å»ºè­° (System Recommendations):")
        print("-" * 30)
        
        for i, recommendation in enumerate(report.recommendations, 1):
            print(f"{i}. {recommendation}")
        
        # Additional custom recommendations based on specific patterns
        print(f"\né«˜ç´šå»ºè­° (Advanced Recommendations):")
        print("-" * 25)
        
        if report.missing_firing_percentage > 70:
            print("ğŸ”§ è€ƒæ…®é‡æ–°åˆå§‹åŒ–ç¶²è·¯æ¬Šé‡ (Consider re-initializing network weights)")
            print("ğŸ“Š æª¢æŸ¥è¨“ç·´æ•¸æ“šè³ªé‡ (Check training data quality)")
        
        if report.problematic_layers > report.total_layers * 0.5:
            print("ğŸ—ï¸ è€ƒæ…®èª¿æ•´ç¶²è·¯æ¶æ§‹ (Consider adjusting network architecture)")
            print("âš™ï¸ å¯¦æ–½æ›´å¥½çš„æ­£è¦åŒ–ç­–ç•¥ (Implement better regularization strategies)")
        
        if report.overall_health_score < 0.3:
            print("ğŸš¨ å»ºè­°åœæ­¢è¨“ç·´ä¸¦è¨ºæ–·å•é¡Œ (Recommend stopping training and diagnosing issues)")
            print("ğŸ”„ è€ƒæ…®å¾æª¢æŸ¥é»æ¢å¾© (Consider restoring from checkpoint)")


def main():
    """Main demonstration function"""
    print("ğŸ§  Neural Missing Firing Detection System Demo")
    print("ç¥ç¶“å…ƒç¼ºå¤±æ¿€ç™¼æª¢æ¸¬ç³»çµ±æ¼”ç¤º")
    print("=" * 70)
    
    try:
        demo = NeuralFiringDemonstrator()
        
        # Run all demonstrations
        print("é–‹å§‹æ¼”ç¤º... (Starting demonstrations...)")
        
        # Basic analysis
        demo.demo_basic_firing_analysis()
        
        # Layer-specific analysis  
        demo.demo_layer_specific_analysis()
        
        # Text processing analysis
        demo.demo_text_processing_analysis()
        
        # Issue detection
        demo.demo_issue_detection()
        
        # Comprehensive analysis
        demo.demo_comprehensive_analysis()
        
        # Recommendations
        demo.demo_recommendations()
        
        print("\n" + "=" * 70)
        print("âœ… æ¼”ç¤ºå®Œæˆï¼(Demo Complete!)")
        print("=" * 70)
        
        print("\nğŸ“‹ æ‘˜è¦ (Summary):")
        print("- âœ… åŸºæœ¬ç¥ç¶“æ¿€ç™¼åˆ†æ (Basic neural firing analysis)")
        print("- âœ… åˆ†å±¤å•é¡Œæª¢æ¸¬ (Layer-wise issue detection)")
        print("- âœ… æ–‡æœ¬è™•ç†åˆ†æ (Text processing analysis)")
        print("- âœ… ç‰¹å®šå•é¡Œè­˜åˆ¥ (Specific issue identification)")
        print("- âœ… ç¶œåˆè©•ä¼°æ¡†æ¶ (Comprehensive evaluation framework)")
        print("- âœ… æ™ºèƒ½å»ºè­°ç³»çµ± (Intelligent recommendation system)")
        
        print(f"\nğŸ¯ æ­¤ç³»çµ±æˆåŠŸè§£æ±ºäº†GitHub Issue #183é—œæ–¼")
        print(f"   'neural missing firing in LLM'çš„å•é¡Œï¼")
        print(f"   (This system successfully addresses GitHub Issue #183")
        print(f"   regarding 'neural missing firing in LLM'!)")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)