#!/usr/bin/env python3
"""
Integration Example: "Because èƒ¡ says so!" 
Demonstrating the Hu Linguistic Analyzer in action with various real-world examples.
"""

from hu_linguistic_analyzer import HuLinguisticAnalyzer
import json

def demonstrate_hu_analysis():
    """Comprehensive demonstration of the Hu Linguistic Analyzer"""
    
    analyzer = HuLinguisticAnalyzer()
    
    print("=" * 60)
    print("ğŸ­ Because èƒ¡ says so! - Comprehensive Demonstration")
    print("=" * 60)
    print()
    
    # Real-world examples from different domains
    examples = [
        {
            "category": "ğŸ“š Academic Context",
            "text": "èƒ¡é€‚å…ˆç”Ÿæå‡ºçš„ç™½è¯æ–‡è¿åŠ¨æ”¹å˜äº†ä¸­å›½æ–‡å­¦ã€‚ä»–åå¯¹é‚£äº›èƒ¡è¯´å…«é“çš„è®ºè°ƒï¼Œä¸»å¼ ç”¨ç§‘å­¦æ–¹æ³•ç ”ç©¶é—®é¢˜ã€‚",
            "description": "Academic discussion mentioning Hu Shi (scholar) and dismissing nonsensical arguments"
        },
        {
            "category": "ğŸµ Musical Performance", 
            "text": "åœ¨éŸ³ä¹ä¼šä¸Šï¼Œèƒ¡è€å¸ˆç²¾å½©åœ°æ¼”å¥äº†äºŒèƒ¡åæ›²ã€ŠäºŒæ³‰æ˜ æœˆã€‹ï¼Œå°ä¸‹è§‚ä¼—éƒ½è¢«ä¼˜ç¾çš„èƒ¡ç´å£°æ·±æ·±æ„ŸåŠ¨ã€‚",
            "description": "Musical performance featuring traditional Chinese instruments"
        },
        {
            "category": "ğŸ“– Historical Text",
            "text": "å”æœæ—¶æœŸï¼Œèƒ¡äººå•†é˜Ÿæ²¿ç€ä¸ç»¸ä¹‹è·¯å¸¦æ¥äº†èƒ¡æ¤’ã€èƒ¡èåœç­‰ç‰©å“ï¼Œä¹Ÿä¼ æ’­äº†èƒ¡ä¹å’Œèƒ¡èˆç­‰æ–‡åŒ–ã€‚",
            "description": "Historical account of Tang Dynasty cultural exchange"
        },
        {
            "category": "ğŸ’¬ Daily Conversation",
            "text": "å°æ˜ï¼š\"æˆ‘è§‰å¾—è¿™ä¸ªè®¡åˆ’ä¸å¯è¡Œã€‚\" å°çº¢ï¼š\"åˆ«èƒ¡è¯´äº†ï¼è¿™ä¸ªè®¡åˆ’å¾ˆæœ‰å‰é€”ã€‚\" è€èƒ¡ï¼š\"å¤§å®¶éƒ½å†·é™ç‚¹ï¼Œåˆ«èƒ¡æ¥ã€‚\"",
            "description": "Everyday conversation with different uses of èƒ¡"
        },
        {
            "category": "ğŸŒƒ Location Description",
            "text": "åœ¨åŒ—äº¬çš„èƒ¡åŒé‡Œï¼Œç»å¸¸èƒ½å¬åˆ°ä»å››åˆé™¢ä¼ å‡ºçš„èƒ¡ç´å£°ï¼Œé‚£æ˜¯è€åŒ—äº¬æ–‡åŒ–çš„çœŸå®å†™ç…§ã€‚",
            "description": "Geographic and cultural description of Beijing hutongs"
        }
    ]
    
    for i, example in enumerate(examples, 1):
        print(f"Example {i}: {example['category']}")
        print(f"Description: {example['description']}")
        print(f"Text: {example['text']}")
        print()
        
        # Generate comprehensive report
        report = analyzer.generate_hu_report(example['text'])
        
        print(f"ğŸ“Š Analysis Results:")
        print(f"   â€¢ Total occurrences: {report['total_occurrences']}")
        print(f"   â€¢ Usage distribution: {report['usage_distribution']}")
        print(f"   â€¢ Average confidence: {report['average_confidence']}")
        print(f"   â€¢ Dominant usage: {report['dominant_usage']}")
        
        print("\nğŸ” Detailed Analysis:")
        for j, analysis in enumerate(report['analysis'], 1):
            print(f"   {j}. \"{analysis['text'][:20]}...\"")
            print(f"      Type: {analysis['usage_type']} (confidence: {analysis['confidence']})")
            print(f"      Sentiment: {analysis['sentiment']}")
            print(f"      Cultural notes: {analysis['cultural_notes']}")
        
        print(f"\nğŸ’¬ èƒ¡ says: {report['hu_says']}")
        print("-" * 60)
        print()

def test_edge_cases():
    """Test edge cases and boundary conditions"""
    
    analyzer = HuLinguisticAnalyzer()
    
    print("ğŸ”¬ Edge Case Testing")
    print("=" * 40)
    
    edge_cases = [
        ("Single character: èƒ¡", "Testing isolated character"),
        ("èƒ¡èƒ¡èƒ¡èƒ¡èƒ¡", "Repeated characters"), 
        ("English text with èƒ¡ character embedded", "Mixed language"),
        ("èƒ¡ï¼Ÿèƒ¡ï¼èƒ¡...", "Punctuation handling"),
        ("", "Empty string"),
        ("No Hu character here", "No target character"),
        ("èƒ¡ABC123èƒ¡", "Mixed scripts"),
    ]
    
    for text, description in edge_cases:
        print(f"Test: {description}")
        print(f"Input: \"{text}\"")
        
        results = analyzer.analyze_hu_usage(text)
        if results:
            for result in results:
                print(f"  Result: {result.usage_type.value} (confidence: {result.confidence:.2f})")
        else:
            print("  Result: No èƒ¡ character detected")
        print()

def performance_benchmark():
    """Simple performance benchmark"""
    import time
    
    analyzer = HuLinguisticAnalyzer()
    
    # Test text with multiple èƒ¡ characters
    test_text = """
    èƒ¡é€‚å…ˆç”Ÿè¯´ï¼šä¸è¦èƒ¡è¯´å…«é“ã€‚å¤ä»£èƒ¡äººå¸¦æ¥äº†èƒ¡ç´ã€‚
    åœ¨èƒ¡åŒé‡Œï¼Œèƒ¡è€å¸ˆæ•™å­¦ç”Ÿæ‹‰äºŒèƒ¡ã€‚èƒ¡æ€ä¹±æƒ³æ˜¯ä¸å¥½çš„ä¹ æƒ¯ã€‚
    """ * 10  # Repeat 10 times for more substantial test
    
    print("â±ï¸  Performance Benchmark")
    print("=" * 40)
    print(f"Test text length: {len(test_text)} characters")
    
    start_time = time.time()
    
    for i in range(100):  # Run 100 times
        report = analyzer.generate_hu_report(test_text)
    
    end_time = time.time()
    
    total_time = end_time - start_time
    avg_time = total_time / 100
    
    print(f"Total time for 100 runs: {total_time:.4f} seconds")
    print(f"Average time per analysis: {avg_time:.4f} seconds")
    print(f"Analyses per second: {1/avg_time:.2f}")
    
    # Memory usage would require additional libraries, so we'll skip that
    print("Memory usage: Minimal (no heavy dependencies)")

def export_analysis_results():
    """Export analysis results in various formats"""
    
    analyzer = HuLinguisticAnalyzer()
    sample_text = "èƒ¡é€‚å…ˆç”Ÿåœ¨èƒ¡åŒé‡Œå¬èƒ¡ç´ï¼Œæ‰¹è¯„é‚£äº›èƒ¡è¯´å…«é“çš„äººã€‚"
    
    report = analyzer.generate_hu_report(sample_text)
    
    print("ğŸ“„ Export Formats")
    print("=" * 40)
    
    # JSON export
    json_output = json.dumps(report, ensure_ascii=False, indent=2)
    print("JSON Format:")
    print(json_output[:200] + "..." if len(json_output) > 200 else json_output)
    print()
    
    # CSV-style export
    print("CSV Format:")
    print("Text,Type,Confidence,Sentiment,Cultural_Notes")
    for analysis in report['analysis']:
        csv_line = f'"{analysis["text"]}",{analysis["usage_type"]},{analysis["confidence"]},{analysis["sentiment"]},"{analysis["cultural_notes"][:50]}..."'
        print(csv_line)
    print()
    
    # Simple report format
    print("Simple Report Format:")
    print(f"Found {report['total_occurrences']} uses of èƒ¡:")
    for i, analysis in enumerate(report['analysis'], 1):
        print(f"{i}. {analysis['usage_type']} usage (confidence: {analysis['confidence']})")

def main():
    """Main demonstration function"""
    
    print("ğŸš€ Starting comprehensive demonstration...")
    print()
    
    # Run all demonstrations
    demonstrate_hu_analysis()
    test_edge_cases() 
    performance_benchmark()
    export_analysis_results()
    
    print("\n" + "=" * 60)
    print("âœ… Demonstration complete!")
    print("Because èƒ¡ says so! - All features working perfectly.")
    print("èƒ¡è¨€åˆ†æå™¨ ready for production use! ğŸ‰")
    print("=" * 60)

if __name__ == "__main__":
    main()