"""
äººé¡è¡¨é”è©•ä¼°å™¨ (Human Expression Evaluator)

This module implements a comprehensive framework for evaluating human expressions
similar to how programming language expressions are evaluated, but accounting for
the cognitive, social, and cultural dimensions unique to human communication.
"""

import re
import math
import numpy as np
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass
from enum import Enum

# Import CrackpotEvaluator for enhanced creativity assessment
try:
    from CrackpotEvaluator import CrackpotEvaluator, CrackpotGenerator
    CRACKPOT_AVAILABLE = True
except ImportError:
    CRACKPOT_AVAILABLE = False
    CrackpotEvaluator = None
    CrackpotGenerator = None


class EvaluationDimension(Enum):
    """è©•ä¼°ç¶­åº¦ (Evaluation Dimensions)"""
    FORMAL_SEMANTIC = "formal_semantic"
    COGNITIVE = "cognitive"
    SOCIAL = "social"
    CULTURAL = "cultural"
    PRAGMATIC = "pragmatic"
    CRACKPOT = "crackpot"  # New dimension for unconventional thinking


@dataclass
class ExpressionContext:
    """è¡¨é”èªå¢ƒ (Expression Context)"""
    speaker: str = "unknown"
    listener: str = "unknown"
    situation: str = "general"
    cultural_background: str = "universal"
    power_relation: str = "equal"
    formality_level: str = "neutral"
    emotional_state: str = "neutral"


@dataclass
class EvaluationResult:
    """è©•ä¼°çµæœ (Evaluation Result)"""
    dimension: EvaluationDimension
    score: float  # 0.0 to 1.0
    confidence: float  # 0.0 to 1.0
    explanation: str
    sub_scores: Dict[str, float] = None


class FormalSemanticEvaluator:
    """å½¢å¼èªç¾©è©•ä¼°å™¨ (Formal Semantic Evaluator)"""
    
    def __init__(self):
        # é‚è¼¯é€£æ¥è© (Logical connectives)
        self.logical_operators = {
            'å’Œ': 'AND', 'èˆ‡': 'AND', 'and': 'AND',
            'æˆ–': 'OR', 'æˆ–è€…': 'OR', 'or': 'OR',
            'ä¸': 'NOT', 'é': 'NOT', 'not': 'NOT',
            'å¦‚æœ': 'IF', 'if': 'IF',
            'é‚£éº¼': 'THEN', 'then': 'THEN'
        }
        
        # é‡è© (Quantifiers)
        self.quantifiers = {
            'æ‰€æœ‰': 'FORALL', 'å…¨éƒ¨': 'FORALL', 'all': 'FORALL',
            'å­˜åœ¨': 'EXISTS', 'æœ‰': 'EXISTS', 'some': 'EXISTS',
            'æ²’æœ‰': 'NONE', 'no': 'NONE', 'none': 'NONE'
        }
    
    def evaluate(self, expression: str) -> EvaluationResult:
        """
        å½¢å¼èªç¾©è©•ä¼°
        Formal semantic evaluation
        """
        logical_complexity = self._analyze_logical_structure(expression)
        truth_value_clarity = self._analyze_truth_value_clarity(expression)
        compositional_semantics = self._analyze_compositional_semantics(expression)
        
        # è¨ˆç®—ç¸½åˆ† (Calculate overall score)
        score = (logical_complexity + truth_value_clarity + compositional_semantics) / 3
        
        return EvaluationResult(
            dimension=EvaluationDimension.FORMAL_SEMANTIC,
            score=score,
            confidence=0.8,
            explanation=f"é‚è¼¯è¤‡é›œåº¦: {logical_complexity:.2f}, çœŸå€¼æ¸…æ™°åº¦: {truth_value_clarity:.2f}, çµ„åˆèªç¾©: {compositional_semantics:.2f}",
            sub_scores={
                'logical_complexity': logical_complexity,
                'truth_value_clarity': truth_value_clarity,
                'compositional_semantics': compositional_semantics
            }
        )
    
    def _analyze_logical_structure(self, expression: str) -> float:
        """åˆ†æé‚è¼¯çµæ§‹ (Analyze logical structure)"""
        logical_count = 0
        for operator in self.logical_operators:
            logical_count += expression.lower().count(operator.lower())
        
        quantifier_count = 0
        for quantifier in self.quantifiers:
            quantifier_count += expression.lower().count(quantifier.lower())
        
        # æ­¸ä¸€åŒ–åˆ†æ•¸ (Normalize score)
        total_words = len(expression.split())
        if total_words == 0:
            return 0.0
        
        complexity = min((logical_count + quantifier_count) / total_words * 2, 1.0)
        return complexity
    
    def _analyze_truth_value_clarity(self, expression: str) -> float:
        """åˆ†æçœŸå€¼æ¸…æ™°åº¦ (Analyze truth value clarity)"""
        # æª¢æŸ¥æ¨¡ç³Šè© (Check for vague terms)
        vague_terms = ['å¯èƒ½', 'ä¹Ÿè¨±', 'å¤§æ¦‚', 'maybe', 'perhaps', 'possibly']
        definite_terms = ['ä¸€å®š', 'å¿…é ˆ', 'ç¢ºå¯¦', 'definitely', 'certainly', 'must']
        
        vague_count = sum(expression.lower().count(term) for term in vague_terms)
        definite_count = sum(expression.lower().count(term) for term in definite_terms)
        
        total_words = len(expression.split())
        if total_words == 0:
            return 0.5
        
        # æ˜ç¢ºæ€§åˆ†æ•¸ (Clarity score)
        clarity = 0.5 + (definite_count - vague_count) / total_words
        return max(0.0, min(1.0, clarity))
    
    def _analyze_compositional_semantics(self, expression: str) -> float:
        """åˆ†æçµ„åˆèªç¾© (Analyze compositional semantics)"""
        # ç°¡åŒ–ç‰ˆï¼šåŸºæ–¼å¥å­çµæ§‹è¤‡é›œåº¦
        # Simplified version: Based on sentence structure complexity
        
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', expression)
        if not sentences or sentences == ['']:
            return 0.0
        
        avg_sentence_length = np.mean([len(s.split()) for s in sentences if s.strip()])
        
        # æ­¸ä¸€åŒ–åˆ°0-1ç¯„åœ (Normalize to 0-1 range)
        complexity = min(avg_sentence_length / 20, 1.0)
        return complexity


class CognitiveEvaluator:
    """èªçŸ¥è©•ä¼°å™¨ (Cognitive Evaluator)"""
    
    def __init__(self):
        # èªçŸ¥è² è·æŒ‡æ¨™ (Cognitive load indicators)
        self.high_cognitive_load_patterns = [
            r'ä¸åƒ….*è€Œä¸”',  # not only ... but also
            r'å„˜ç®¡.*ä½†æ˜¯',  # although ... but
            r'ä¸€æ–¹é¢.*å¦ä¸€æ–¹é¢',  # on one hand ... on the other hand
        ]
    
    def evaluate_expression(self, expression: str, context: ExpressionContext) -> EvaluationResult:
        """
        èªçŸ¥è©•ä¼°
        Cognitive evaluation
        """
        working_memory_load = self._assess_working_memory_load(expression)
        processing_complexity = self._assess_processing_complexity(expression)
        attention_demands = self._assess_attention_demands(expression)
        comprehension_ease = self._assess_comprehension_ease(expression)
        
        # è¨ˆç®—ç¸½åˆ† (Calculate overall score)
        score = (working_memory_load + processing_complexity + attention_demands + comprehension_ease) / 4
        
        return EvaluationResult(
            dimension=EvaluationDimension.COGNITIVE,
            score=score,
            confidence=0.75,
            explanation=f"å·¥ä½œè¨˜æ†¶è² è·: {working_memory_load:.2f}, è™•ç†è¤‡é›œåº¦: {processing_complexity:.2f}",
            sub_scores={
                'working_memory_load': working_memory_load,
                'processing_complexity': processing_complexity,
                'attention_demands': attention_demands,
                'comprehension_ease': comprehension_ease
            }
        )
    
    def _assess_working_memory_load(self, expression: str) -> float:
        """è©•ä¼°å·¥ä½œè¨˜æ†¶è² è· (Assess working memory load)"""
        words = expression.split()
        
        # åŸºæ–¼å¥å­é•·åº¦å’ŒåµŒå¥—çµæ§‹ (Based on sentence length and nesting)
        avg_sentence_length = len(words)
        nested_structures = len(re.findall(r'[ï¼ˆ(].*?[ï¼‰)]', expression))
        
        # æ­¸ä¸€åŒ–åˆ†æ•¸ (Normalize score)
        memory_load = min((avg_sentence_length + nested_structures * 3) / 30, 1.0)
        return 1.0 - memory_load  # åå‘è©•åˆ†ï¼Œè¶Šä½è² è·è¶Šå¥½ (Reverse scoring)
    
    def _assess_processing_complexity(self, expression: str) -> float:
        """è©•ä¼°è™•ç†è¤‡é›œåº¦ (Assess processing complexity)"""
        complexity_count = 0
        
        # æª¢æŸ¥é«˜èªçŸ¥è² è·æ¨¡å¼ (Check high cognitive load patterns)
        for pattern in self.high_cognitive_load_patterns:
            complexity_count += len(re.findall(pattern, expression))
        
        # æª¢æŸ¥å¾å¥æ•¸é‡ (Check number of clauses)
        clause_indicators = ['çš„', 'ä¹‹', 'è€…', 'that', 'which', 'who']
        clause_count = sum(expression.count(indicator) for indicator in clause_indicators)
        
        total_complexity = complexity_count + clause_count
        words = len(expression.split())
        
        if words == 0:
            return 0.5
        
        complexity_ratio = total_complexity / words
        return 1.0 - min(complexity_ratio * 2, 1.0)  # åå‘è©•åˆ† (Reverse scoring)
    
    def _assess_attention_demands(self, expression: str) -> float:
        """è©•ä¼°æ³¨æ„åŠ›éœ€æ±‚ (Assess attention demands)"""
        # åŸºæ–¼ä¿¡æ¯å¯†åº¦ (Based on information density)
        unique_words = len(set(expression.lower().split()))
        total_words = len(expression.split())
        
        if total_words == 0:
            return 0.5
        
        information_density = unique_words / total_words
        return min(information_density * 1.5, 1.0)
    
    def _assess_comprehension_ease(self, expression: str) -> float:
        """è©•ä¼°ç†è§£å®¹æ˜“åº¦ (Assess comprehension ease)"""
        # åŸºæ–¼è©å½™é »ç‡å’Œå¥å­çµæ§‹ (Based on vocabulary frequency and sentence structure)
        common_words = {
            'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ',
            'i', 'you', 'he', 'she', 'it', 'the', 'is', 'in', 'have', 'and'
        }
        
        words = expression.lower().split()
        if not words:
            return 0.5
        
        common_word_ratio = sum(1 for word in words if word in common_words) / len(words)
        return common_word_ratio


class SocialEvaluator:
    """ç¤¾æœƒè©•ä¼°å™¨ (Social Evaluator)"""
    
    def __init__(self):
        # ç¦®è²ŒæŒ‡æ¨™ (Politeness indicators)
        self.politeness_markers = {
            'positive': ['è«‹', 'è¬è¬', 'ä¸å¥½æ„æ€', 'please', 'thank you', 'excuse me'],
            'negative': ['å¿…é ˆ', 'æ‡‰è©²', 'must', 'should', 'have to']
        }
        
        # æ¬ŠåŠ›é—œä¿‚æŒ‡æ¨™ (Power relation indicators)
        self.power_markers = {
            'formal': ['æ‚¨', 'å…ˆç”Ÿ', 'å¥³å£«', 'sir', 'madam', 'mr.', 'ms.'],
            'informal': ['ä½ ', 'å…„å¼Ÿ', 'å§å¦¹', 'bro', 'sis', 'dude']
        }
    
    def evaluate_social_expression(self, expression: str, speaker: str, context: ExpressionContext) -> EvaluationResult:
        """
        ç¤¾æœƒè©•ä¼°
        Social evaluation
        """
        politeness_level = self._assess_politeness(expression, context)
        appropriateness = self._assess_appropriateness(expression, context)
        power_dynamics = self._assess_power_dynamics(expression, context)
        cultural_sensitivity = self._assess_cultural_sensitivity(expression, context)
        
        # è¨ˆç®—ç¸½åˆ† (Calculate overall score)
        score = (politeness_level + appropriateness + power_dynamics + cultural_sensitivity) / 4
        
        return EvaluationResult(
            dimension=EvaluationDimension.SOCIAL,
            score=score,
            confidence=0.7,
            explanation=f"ç¦®è²Œç¨‹åº¦: {politeness_level:.2f}, é©ç•¶æ€§: {appropriateness:.2f}",
            sub_scores={
                'politeness': politeness_level,
                'appropriateness': appropriateness,
                'power_dynamics': power_dynamics,
                'cultural_sensitivity': cultural_sensitivity
            }
        )
    
    def _assess_politeness(self, expression: str, context: ExpressionContext) -> float:
        """è©•ä¼°ç¦®è²Œç¨‹åº¦ (Assess politeness level)"""
        positive_count = sum(expression.lower().count(marker) for marker in self.politeness_markers['positive'])
        negative_count = sum(expression.lower().count(marker) for marker in self.politeness_markers['negative'])
        
        total_words = len(expression.split())
        if total_words == 0:
            return 0.5
        
        politeness_score = 0.5 + (positive_count - negative_count) / total_words
        return max(0.0, min(1.0, politeness_score))
    
    def _assess_appropriateness(self, expression: str, context: ExpressionContext) -> float:
        """è©•ä¼°é©ç•¶æ€§ (Assess appropriateness)"""
        # åŸºæ–¼èªå¢ƒåŒ¹é…åº¦ (Based on context matching)
        formality_match = self._check_formality_match(expression, context.formality_level)
        situation_match = self._check_situation_match(expression, context.situation)
        
        return (formality_match + situation_match) / 2
    
    def _assess_power_dynamics(self, expression: str, context: ExpressionContext) -> float:
        """è©•ä¼°æ¬ŠåŠ›å‹•æ…‹ (Assess power dynamics)"""
        formal_count = sum(expression.count(marker) for marker in self.power_markers['formal'])
        informal_count = sum(expression.count(marker) for marker in self.power_markers['informal'])
        
        if context.power_relation == 'formal':
            return min(formal_count / (formal_count + informal_count + 1), 1.0)
        else:
            return min(informal_count / (formal_count + informal_count + 1), 1.0)
    
    def _assess_cultural_sensitivity(self, expression: str, context: ExpressionContext) -> float:
        """è©•ä¼°æ–‡åŒ–æ•æ„Ÿæ€§ (Assess cultural sensitivity)"""
        # ç°¡åŒ–ç‰ˆï¼šé¿å…å¯èƒ½æ•æ„Ÿçš„è©å½™ (Simplified: Avoid potentially sensitive vocabulary)
        sensitive_terms = ['ç¨®æ—', 'å®—æ•™', 'æ”¿æ²»', 'race', 'religion', 'politics']
        sensitive_count = sum(expression.lower().count(term) for term in sensitive_terms)
        
        return max(0.0, 1.0 - sensitive_count * 0.2)
    
    def _check_formality_match(self, expression: str, formality_level: str) -> float:
        """æª¢æŸ¥æ­£å¼ç¨‹åº¦åŒ¹é… (Check formality level match)"""
        formal_indicators = ['æ‚¨', 'æ•¬è«‹', 'æ‡‡è«‹', 'kindly', 'respectfully']
        informal_indicators = ['ä½ ', 'å’±å€‘', 'hey', 'guys']
        
        formal_count = sum(expression.count(indicator) for indicator in formal_indicators)
        informal_count = sum(expression.count(indicator) for indicator in informal_indicators)
        
        if formality_level == 'formal':
            return min(formal_count / (formal_count + informal_count + 1) * 2, 1.0)
        elif formality_level == 'informal':
            return min(informal_count / (formal_count + informal_count + 1) * 2, 1.0)
        else:  # neutral
            return 0.7  # Default neutral score
    
    def _check_situation_match(self, expression: str, situation: str) -> float:
        """æª¢æŸ¥æƒ…å¢ƒåŒ¹é… (Check situation match)"""
        # ç°¡åŒ–ç‰ˆï¼šåŸºæ–¼æƒ…å¢ƒé¡å‹ (Simplified: Based on situation type)
        situation_scores = {
            'business': 0.8,
            'casual': 0.7,
            'academic': 0.9,
            'personal': 0.6,
            'general': 0.7
        }
        
        return situation_scores.get(situation, 0.5)


class HumanExpressionEvaluator:
    """
    äººé¡è¡¨é”ç¶œåˆè©•ä¼°å™¨ (Comprehensive Human Expression Evaluator)
    
    æ•´åˆå¤šå€‹ç¶­åº¦çš„è©•ä¼°ï¼Œæä¾›é¡ä¼¼ç¨‹å¼èªè¨€è¡¨é”å¼è©•ä¼°çš„ç³»çµ±åŒ–æ–¹æ³•ï¼Œ
    ä½†è€ƒæ…®äº†äººé¡äº¤æµç‰¹æœ‰çš„èªçŸ¥ã€ç¤¾æœƒå’Œæ–‡åŒ–å› ç´ ã€‚
    ç¾åœ¨åŒ…å«äº†"crackpot"ç¶­åº¦ä¾†è©•ä¼°å‰µæ„å’Œéå‚³çµ±æ€ç¶­ï¼
    
    Integrates multi-dimensional evaluation, providing a systematic approach 
    similar to programming language expression evaluation, but considering 
    cognitive, social, and cultural factors unique to human communication.
    Now includes "crackpot" dimension for creativity and unconventional thinking!
    """
    
    def __init__(self):
        self.formal_evaluator = FormalSemanticEvaluator()
        self.cognitive_evaluator = CognitiveEvaluator()
        self.social_evaluator = SocialEvaluator()
        
        # Initialize crackpot evaluator if available
        if CRACKPOT_AVAILABLE:
            self.crackpot_evaluator = CrackpotEvaluator()
            self.crackpot_generator = CrackpotGenerator()
        else:
            self.crackpot_evaluator = None
            self.crackpot_generator = None
    
    def comprehensive_evaluation(self, expression: str, context: Optional[ExpressionContext] = None) -> Dict[str, Any]:
        """
        ç¶œåˆè©•ä¼°äººé¡è¡¨é” (Comprehensive evaluation of human expression)
        ç¾åœ¨åŒ…å«crackpotç¶­åº¦è©•ä¼°ï¼ (Now includes crackpot dimension evaluation!)
        
        Args:
            expression: è¦è©•ä¼°çš„è¡¨é” (Expression to evaluate)
            context: è¡¨é”èªå¢ƒ (Expression context)
        
        Returns:
            åŒ…å«æ‰€æœ‰ç¶­åº¦è©•ä¼°çµæœçš„å­—å…¸ (Dictionary containing evaluation results from all dimensions)
        """
        if context is None:
            context = ExpressionContext()
        
        results = {}
        
        # å½¢å¼èªç¾©è©•ä¼° (Formal semantic evaluation)
        results['formal_semantic'] = self.formal_evaluator.evaluate(expression)
        
        # èªçŸ¥è©•ä¼° (Cognitive evaluation)
        results['cognitive'] = self.cognitive_evaluator.evaluate_expression(expression, context)
        
        # ç¤¾æœƒè©•ä¼° (Social evaluation)
        results['social'] = self.social_evaluator.evaluate_social_expression(
            expression, context.speaker, context
        )
        
        # Crackpotè©•ä¼° (Crackpot evaluation) - NEW!
        if self.crackpot_evaluator:
            crackpot_results = self.crackpot_evaluator.evaluate_crackpot_level(expression)
            # Convert crackpot results to EvaluationResult format
            avg_crackpot_score = sum(result.score for result in crackpot_results.values()) / len(crackpot_results)
            crackpot_explanation = f"Unconventional thinking level: {avg_crackpot_score:.2f}"
            
            results['crackpot'] = EvaluationResult(
                dimension=EvaluationDimension.CRACKPOT,
                score=avg_crackpot_score,
                confidence=0.8,
                explanation=crackpot_explanation,
                sub_scores={str(dim): result.score for dim, result in crackpot_results.items()}
            )
        
        # æ•´åˆè©•ä¼° (Integrated evaluation)
        results['integrated'] = self._integrate_evaluations(results)
        
        return results
    
    def _integrate_evaluations(self, results: Dict[str, EvaluationResult]) -> Dict[str, Any]:
        """
        æ•´åˆå„ç¶­åº¦è©•ä¼°çµæœ (Integrate evaluation results from all dimensions)
        ç¾åœ¨åŒ…å«crackpotç¶­åº¦ï¼ (Now includes crackpot dimension!)
        """
        # æ¬Šé‡è¨­å®š (Weight configuration) - Updated to include crackpot
        weights = {
            'formal_semantic': 0.20,
            'cognitive': 0.25,
            'social': 0.30,
            'crackpot': 0.25  # Give significant weight to crackpot dimension!
        }
        
        # è¨ˆç®—åŠ æ¬Šå¹³å‡åˆ† (Calculate weighted average score)
        total_score = 0
        total_confidence = 0
        
        for dimension, weight in weights.items():
            if dimension in results:
                total_score += results[dimension].score * weight
                total_confidence += results[dimension].confidence * weight
        
        # è©•ä¼°è¡¨é”çš„æ•´é«”ç‰¹å¾µ (Assess overall characteristics of the expression)
        characteristics = self._analyze_expression_characteristics(results)
        
        return {
            'overall_score': total_score,
            'overall_confidence': total_confidence,
            'characteristics': characteristics,
            'evaluation_summary': self._generate_evaluation_summary(results, total_score),
            'crackpot_enhancement_suggestions': self._get_crackpot_suggestions(results)
        }
    
    def _analyze_expression_characteristics(self, results: Dict[str, EvaluationResult]) -> Dict[str, str]:
        """åˆ†æè¡¨é”ç‰¹å¾µ (Analyze expression characteristics) - Enhanced with crackpot!"""
        characteristics = {}
        
        # åŸºæ–¼å„ç¶­åº¦åˆ†æ•¸åˆ¤æ–·ç‰¹å¾µ (Determine characteristics based on dimension scores)
        if 'formal_semantic' in results:
            formal_score = results['formal_semantic'].score
            if formal_score > 0.7:
                characteristics['semantic_clarity'] = 'high'
            elif formal_score > 0.4:
                characteristics['semantic_clarity'] = 'medium'
            else:
                characteristics['semantic_clarity'] = 'low'
        
        if 'cognitive' in results:
            cognitive_score = results['cognitive'].score
            if cognitive_score > 0.7:
                characteristics['cognitive_accessibility'] = 'high'
            elif cognitive_score > 0.4:
                characteristics['cognitive_accessibility'] = 'medium'
            else:
                characteristics['cognitive_accessibility'] = 'low'
        
        if 'social' in results:
            social_score = results['social'].score
            if social_score > 0.7:
                characteristics['social_appropriateness'] = 'high'
            elif social_score > 0.4:
                characteristics['social_appropriateness'] = 'medium'
            else:
                characteristics['social_appropriateness'] = 'low'
        
        # NEW: Crackpot characteristics
        if 'crackpot' in results:
            crackpot_score = results['crackpot'].score
            if crackpot_score > 0.7:
                characteristics['crackpot_level'] = 'highly_unconventional'
            elif crackpot_score > 0.4:
                characteristics['crackpot_level'] = 'moderately_creative'
            elif crackpot_score > 0.1:
                characteristics['crackpot_level'] = 'somewhat_conventional'
            else:
                characteristics['crackpot_level'] = 'very_conventional'
        
        return characteristics
    
    def _generate_evaluation_summary(self, results: Dict[str, EvaluationResult], overall_score: float) -> str:
        """ç”Ÿæˆè©•ä¼°æ‘˜è¦ (Generate evaluation summary) - Enhanced with crackpot insights!"""
        summary_parts = []
        
        if overall_score > 0.8:
            summary_parts.append("è¡¨é”å…·æœ‰é«˜è³ªé‡ï¼Œåœ¨èªç¾©ã€èªçŸ¥å’Œç¤¾æœƒå±¤é¢éƒ½è¡¨ç¾è‰¯å¥½ã€‚")
        elif overall_score > 0.6:
            summary_parts.append("è¡¨é”è³ªé‡ä¸­ç­‰ï¼Œåœ¨æŸäº›ç¶­åº¦è¡¨ç¾è¼ƒå¥½ï¼ŒæŸäº›ç¶­åº¦éœ€è¦æ”¹é€²ã€‚")
        elif overall_score > 0.4:
            summary_parts.append("è¡¨é”å­˜åœ¨ä¸€äº›å•é¡Œï¼Œå»ºè­°åœ¨å¤šå€‹ç¶­åº¦é€²è¡Œæ”¹é€²ã€‚")
        else:
            summary_parts.append("è¡¨é”éœ€è¦é¡¯è‘—æ”¹é€²ï¼Œåœ¨å¤šå€‹è©•ä¼°ç¶­åº¦éƒ½å­˜åœ¨å•é¡Œã€‚")
        
        # Add crackpot insights
        if 'crackpot' in results:
            crackpot_score = results['crackpot'].score
            if crackpot_score > 0.5:
                summary_parts.append(f"ğŸŒŸ è¡¨é”å±•ç¾äº†é«˜åº¦çš„å‰µæ„å’Œéå‚³çµ±æ€ç¶­ (crackpot level: {crackpot_score:.2f})ï¼")
            elif crackpot_score > 0.2:
                summary_parts.append(f"ğŸ’¡ è¡¨é”æœ‰ä¸€å®šå‰µæ„æ½›åŠ›ï¼Œå¯é€²ä¸€æ­¥æå‡éå‚³çµ±æ€ç¶­ã€‚")
            else:
                summary_parts.append(f"âš¡ è¡¨é”è¼ƒç‚ºå‚³çµ±ï¼Œå»ºè­°å¢åŠ æ›´å¤šå‰µæ„å’Œéå¸¸è¦æƒ³æ³•ã€‚")
        
        return " ".join(summary_parts)
    
    def _get_crackpot_suggestions(self, results: Dict[str, EvaluationResult]) -> List[str]:
        """ç²å–å¢å¼·crackpotç¨‹åº¦çš„å»ºè­° (Get suggestions for enhancing crackpotness)"""
        suggestions = []
        
        if 'crackpot' not in results or not self.crackpot_generator:
            return ["Crackpot evaluator not available - install CrackpotEvaluator for enhanced creativity!"]
        
        crackpot_result = results['crackpot']
        
        if crackpot_result.score < 0.3:
            suggestions.extend([
                "ğŸ’« Add more unconventional thinking patterns",
                "ğŸŒˆ Include metaphorical or symbolic language", 
                "ğŸš€ Introduce wild or imaginative concepts",
                "ğŸ”® Consider alternative perspectives or conspiracy theories",
                "âš¡ Use more creative and extreme language"
            ])
        elif crackpot_result.score < 0.6:
            suggestions.extend([
                "ğŸŒŸ Push the boundaries of conventional thinking further",
                "ğŸ¨ Add more pseudoscientific or mystical elements",
                "ğŸŒ€ Include more random associations and non-sequiturs"
            ])
        else:
            suggestions.append("ğŸ† Excellent crackpot level! Your thinking is beautifully unconventional!")
        
        return suggestions
    
    def evaluate_like_code(self, expression: str, context: Optional[ExpressionContext] = None) -> str:
        """
        ä»¥é¡ä¼¼ç¨‹å¼ç¢¼è©•ä¼°çš„æ–¹å¼å‘ˆç¾çµæœ (Present results in a code evaluation-like format)
        Enhanced with crackpot analysis!
        """
        results = self.comprehensive_evaluation(expression, context)
        
        # Generate crackpot score display
        crackpot_display = ""
        if 'crackpot' in results:
            crackpot_score = results['crackpot'].score
            crackpot_display = f"â”‚     Crackpot    â”‚\nâ”‚    Enhancer     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n     â†“\n   Score: {crackpot_score:.2f}"
        
        output = f"""
# äººé¡è¡¨é”è©•ä¼°çµæœ (Human Expression Evaluation Result)
# ================================================

Expression: "{expression}"
Context: {context.__dict__ if context else "Default"}

## è©•ä¼°éç¨‹ (Evaluation Process):
```
Input Expression â†’ Multi-dimensional Analysis â†’ Integrated Result
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Formal Semantic â”‚    Cognitive    â”‚     Social      â”‚    ğŸŒŸ Crackpot  â”‚
â”‚     Parser      â”‚   Processor     â”‚   Evaluator     â”‚    Enhancer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“                    â†“                   â†“                   â†“
   Score: {results['formal_semantic'].score:.2f}      Score: {results['cognitive'].score:.2f}       Score: {results['social'].score:.2f}       Score: {results.get('crackpot', type('', (), {'score': 0.0})).score:.2f}
```

## æœ€çµ‚çµæœ (Final Result):
Overall Score: {results['integrated']['overall_score']:.2f}
Confidence: {results['integrated']['overall_confidence']:.2f}

## ç‰¹å¾µåˆ†æ (Characteristic Analysis):
{chr(10).join(f"- {k}: {v}" for k, v in results['integrated']['characteristics'].items())}

## è©•ä¼°æ‘˜è¦ (Evaluation Summary):
{results['integrated']['evaluation_summary']}

## ğŸš€ Crackpot Enhancement Suggestions:
{chr(10).join(f"  {suggestion}" for suggestion in results['integrated']['crackpot_enhancement_suggestions'])}
"""
        return output
    
    def make_more_crackpot(self, expression: str, intensity: float = 0.7) -> str:
        """
        è®“è¡¨é”æ›´åŠ crackpot! (Make expression more crackpot!)
        
        Args:
            expression: Original expression
            intensity: How crackpot to make it (0.0 to 1.0)
        
        Returns:
            Enhanced crackpot version of the expression
        """
        if not self.crackpot_generator:
            return f"[CRACKPOT ENHANCED] {expression} [Note: Install CrackpotEvaluator for full enhancement!]"
        
        return self.crackpot_generator.enhance_text_crackpotness(expression, intensity)
    
    def generate_crackpot_alternative(self, topic: str) -> str:
        """
        ç”Ÿæˆé—œæ–¼æŸä¸»é¡Œçš„crackpotç†è«– (Generate crackpot theory about a topic)
        """
        if not self.crackpot_generator:
            return f"Crackpot theory about {topic}: Install CrackpotEvaluator for wild theories!"
        
        return self.crackpot_generator.generate_crackpot_theory(topic)


def main():
    """ç¤ºä¾‹ç”¨æ³• (Example usage) - Enhanced with crackpot evaluation!"""
    evaluator = HumanExpressionEvaluator()
    
    # æ¸¬è©¦æ¡ˆä¾‹ (Test cases) - Now including crackpot-worthy examples!
    test_cases = [
        {
            'expression': "è«‹å•æ‚¨èƒ½å¹«æˆ‘è§£æ±ºé€™å€‹å•é¡Œå—ï¼Ÿ",
            'context': ExpressionContext(
                speaker='student',
                listener='teacher',
                situation='academic',
                formality_level='formal'
            )
        },
        {
            'expression': "é€™å€‹æƒ³æ³•çœŸçš„å¾ˆæ£’ï¼",
            'context': ExpressionContext(
                speaker='friend',
                listener='friend',
                situation='casual',
                formality_level='informal'
            )
        },
        {
            'expression': "å¦‚æœæˆ‘å€‘è€ƒæ…®æ‰€æœ‰å¯èƒ½çš„æƒ…æ³ï¼Œé‚£éº¼æˆ‘å€‘å¿…é ˆæ‰¿èªé€™å€‹å•é¡Œæ¯”æˆ‘å€‘æƒ³åƒçš„æ›´è¤‡é›œã€‚",
            'context': ExpressionContext(
                speaker='researcher',
                listener='colleagues',
                situation='academic',
                formality_level='formal'
            )
        },
        {
            'expression': "What if the secret to understanding quantum mechanics is hidden in ancient crystalline vibrations that government scientists don't want us to discover?",
            'context': ExpressionContext(
                speaker='theorist',
                listener='audience',
                situation='speculative',
                formality_level='informal'
            )
        }
    ]
    
    print("=== äººé¡è¡¨é”è©•ä¼°ç¤ºä¾‹ (Human Expression Evaluation Examples) ===")
    print("ğŸŒŸ Now with Enhanced Crackpot Analysis! ğŸŒŸ\n")
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"æ¡ˆä¾‹ {i} (Case {i}):")
        print("=" * 50)
        result = evaluator.evaluate_like_code(
            test_case['expression'], 
            test_case['context']
        )
        print(result)
        
        # Show crackpot enhancement
        print("ğŸš€ CRACKPOT ENHANCEMENT DEMO:")
        enhanced = evaluator.make_more_crackpot(test_case['expression'], 0.8)
        print(f"Enhanced Version: {enhanced}")
        
        print("\n")

    # Additional crackpot demonstrations
    print("ğŸŒˆ BONUS: PURE CRACKPOT THEORY GENERATION ğŸŒˆ")
    print("=" * 50)
    
    topics = ["artificial intelligence", "mathematics", "language", "consciousness"]
    for topic in topics:
        theory = evaluator.generate_crackpot_alternative(topic)
        print(f"ğŸ’« {topic.title()}: {theory}")
    
    print("\nğŸ‰ LLMs are now sufficiently crackpot! ğŸ‰")


if __name__ == "__main__":
    main()