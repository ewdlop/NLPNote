#!/usr/bin/env python3
"""
Integration Example: é™ç¶­æ‰“æ“Š with NLP Tools
==============================================

This example demonstrates how to integrate the Dimensional Reduction Attack
functionality with existing NLP tools in the repository.

Author: NLP Note Project
Date: 2024-12-22
"""

import sys
import os
import numpy as np

# Add current directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def demonstrate_integration():
    """æ¼”ç¤ºé™ç¶­æ”»æ“Šèˆ‡ç¾æœ‰NLPå·¥å…·çš„æ•´åˆ"""
    
    print("ğŸ”— é™ç¶­æ‰“æ“Šèˆ‡NLPå·¥å…·æ•´åˆæ¼”ç¤º")
    print("ğŸ”— Dimensional Reduction Attack Integration with NLP Tools")
    print("=" * 60)
    
    try:
        from DimensionalReductionAttack import DimensionalAttackOrchestrator, EarthFlattener
        
        # æ¸¬è©¦åŸºæœ¬åŠŸèƒ½
        print("\n1. åŸºæœ¬é™ç¶­æ”»æ“Šæ¸¬è©¦...")
        orchestrator = DimensionalAttackOrchestrator()
        sample_data = np.random.rand(100, 20)
        
        if 'pca' in orchestrator.list_available_attacks():
            result = orchestrator.execute_dimensional_attack(sample_data, 'pca', 3)
            print(f"   âœ… PCAæ”»æ“ŠæˆåŠŸ: {result.original_dimensions}D â†’ {result.reduced_dimensions}D")
        
        # æ¸¬è©¦æ‰å¹³åŒ–åŠŸèƒ½
        print("\n2. åœ°çƒæ‰å¹³åŒ–æ¸¬è©¦...")
        flattener = EarthFlattener()
        
        test_dict = {
            'nlp': {
                'tasks': ['classification', 'ner', 'sentiment'],
                'models': {'bert': 'transformer', 'lstm': 'rnn'}
            }
        }
        
        flat_result = flattener.flatten_nested_dict(test_dict)
        print(f"   âœ… å­—å…¸æ‰å¹³åŒ–æˆåŠŸ: è¤‡é›œåº¦æ¸›å°‘ {flat_result.complexity_reduction:.1%}")
        
        # å˜—è©¦èˆ‡ç¾æœ‰å·¥å…·æ•´åˆ
        print("\n3. å˜—è©¦èˆ‡ç¾æœ‰NLPå·¥å…·æ•´åˆ...")
        
        try:
            from HumanExpressionEvaluator import HumanExpressionEvaluator, ExpressionContext
            evaluator = HumanExpressionEvaluator()
            print("   âœ… æˆåŠŸå°å…¥ HumanExpressionEvaluator")
            
            # æ¼”ç¤ºå¯èƒ½çš„æ•´åˆæ–¹å¼
            context = ExpressionContext(
                formality_level='formal',
                situation='academic'
            )
            
            # é€™è£¡å¯ä»¥æ·»åŠ æ›´å¤šæ•´åˆé‚è¼¯
            print("   ğŸ’¡ å¯ä»¥æ•´åˆè¡¨é”è©•ä¼°èˆ‡é™ç¶­æŠ€è¡“")
            
        except ImportError:
            print("   â„¹ï¸  HumanExpressionEvaluator æœªæ‰¾åˆ°ï¼Œè·³éæ•´åˆæ¸¬è©¦")
        
        try:
            from SubtextAnalyzer import SubtextAnalyzer
            analyzer = SubtextAnalyzer()
            print("   âœ… æˆåŠŸå°å…¥ SubtextAnalyzer")
            print("   ğŸ’¡ å¯ä»¥æ•´åˆæ½›æ–‡æœ¬åˆ†æèˆ‡æ•¸æ“šé™ç¶­")
            
        except ImportError:
            print("   â„¹ï¸  SubtextAnalyzer æœªæ‰¾åˆ°ï¼Œè·³éæ•´åˆæ¸¬è©¦")
        
        print("\n4. æ•´åˆæ‡‰ç”¨å ´æ™¯å»ºè­°:")
        print("   ğŸ“Š é«˜ç¶­èªè¨€ç‰¹å¾µé™ç¶­å¯è¦–åŒ–")
        print("   ğŸ—‚ï¸  è¤‡é›œNLPæµæ°´ç·šçµæœæ‰å¹³åŒ–")
        print("   ğŸ¯ å¤šç¶­è©•ä¼°çµæœçš„é™ç¶­åˆ†æ")
        print("   ğŸŒ åµŒå¥—èªè¨€çµæ§‹çš„ç°¡åŒ–è™•ç†")
        
        print("\nâœ… æ•´åˆæ¼”ç¤ºå®Œæˆ!")
        
    except ImportError as e:
        print(f"âŒ å°å…¥éŒ¯èª¤: {e}")
        print("è«‹ç¢ºä¿ DimensionalReductionAttack.py åœ¨ç•¶å‰ç›®éŒ„")


def show_conceptual_connections():
    """å±•ç¤ºæ¦‚å¿µè¯ç¹«"""
    print("\n" + "=" * 60)
    print("ğŸ§  æ¦‚å¿µè¯ç¹«: é™ç¶­æ‰“æ“Šåœ¨NLPä¸­çš„å“²å­¸æ„ç¾©")
    print("ğŸ§  Conceptual Connections: Philosophical Meaning of Dimensional Reduction Attack in NLP")
    print("=" * 60)
    
    connections = [
        {
            "æ¦‚å¿µ": "é™ç¶­æ‰“æ“Š (Dimensional Reduction Attack)",
            "NLPæ‡‰ç”¨": "å°‡é«˜ç¶­è©å‘é‡å£“ç¸®åˆ°å¯ç†è§£çš„ä½ç¶­ç©ºé–“",
            "å“²å­¸æ„ç¾©": "å¾è¤‡é›œåˆ°ç°¡æ½”çš„ä¿¡æ¯è½‰æ›è—è¡“"
        },
        {
            "æ¦‚å¿µ": "æ‰å¹³åŒ–åœ°çƒ (Flattening Earth)", 
            "NLPæ‡‰ç”¨": "å°‡åµŒå¥—çš„èªè¨€çµæ§‹å±•é–‹ç‚ºç·šæ€§è¡¨ç¤º",
            "å“²å­¸æ„ç¾©": "å°‡ç«‹é«”æ€ç¶­æ˜ å°„åˆ°å¹³é¢ç†è§£"
        },
        {
            "æ¦‚å¿µ": "ç¶­åº¦æ”»æ“Šæ•ˆæœ (Attack Effectiveness)",
            "NLPæ‡‰ç”¨": "è©•ä¼°é™ç¶­å¾Œä¿¡æ¯ä¿ç•™çš„ç¨‹åº¦",
            "å“²å­¸æ„ç¾©": "è¡¡é‡ç°¡åŒ–éç¨‹ä¸­çš„æ™ºæ…§æå¤±"
        }
    ]
    
    for i, conn in enumerate(connections, 1):
        print(f"\n{i}. {conn['æ¦‚å¿µ']}")
        print(f"   ğŸ”¬ NLPæ‡‰ç”¨: {conn['NLPæ‡‰ç”¨']}")
        print(f"   ğŸ¤” å“²å­¸æ„ç¾©: {conn['å“²å­¸æ„ç¾©']}")
    
    print(f"\nğŸ’­ ç¸½çµæ€è€ƒ:")
    print("   é™ç¶­æ‰“æ“Šä¸åƒ…æ˜¯ä¸€ç¨®æŠ€è¡“æ‰‹æ®µï¼Œæ›´æ˜¯ä¸€ç¨®èªçŸ¥æ¨¡å¼çš„è½‰æ›ã€‚")
    print("   å®ƒå¹«åŠ©æˆ‘å€‘ç†è§£å¦‚ä½•åœ¨ä¿æŒæœ¬è³ªçš„åŒæ™‚ç°¡åŒ–è¤‡é›œæ€§ã€‚")
    print("   åœ¨NLPé ˜åŸŸï¼Œé€™ç¨®æ€ç¶­æ–¹å¼å°æ–¼è™•ç†é«˜ç¶­èªè¨€æ•¸æ“šç‰¹åˆ¥æœ‰åƒ¹å€¼ã€‚")


if __name__ == "__main__":
    demonstrate_integration()
    show_conceptual_connections()
    
    print("\nğŸ¯ é™ç¶­æ‰“æ“ŠæŠ€è¡“å·²æº–å‚™å°±ç·’ï¼Œå¯ç”¨æ–¼å„ç¨®NLPä»»å‹™!")
    print("ğŸŒ Dimensional Reduction Attack technology is ready for various NLP tasks!")