#!/usr/bin/env python3
"""
æˆ‘çš„å­—ç¬¦ç€è¦½å™¨ (My Characters Browser)

An interactive tool for exploring and analyzing characters in the NLP repository.
äº’å‹•å¼å·¥å…·ï¼Œç”¨æ–¼æ¢ç´¢å’Œåˆ†æNLPå­˜å„²åº«ä¸­çš„å­—ç¬¦ã€‚
"""

import sys
import argparse
from CharacterAnalyzer import CharacterAnalyzer, WritingSystem
from HumanExpressionEvaluator import HumanExpressionEvaluator, ExpressionContext


class CharacterBrowser:
    """å­—ç¬¦ç€è¦½å™¨ (Character Browser)"""
    
    def __init__(self):
        self.analyzer = CharacterAnalyzer()
        self.expression_evaluator = HumanExpressionEvaluator()
        self.current_results = None
        
    def load_repository_analysis(self):
        """åŠ è¼‰å­˜å„²åº«åˆ†æ (Load repository analysis)"""
        print("ğŸ” æ­£åœ¨åˆ†æå­˜å„²åº«å­—ç¬¦... (Analyzing repository characters...)")
        self.current_results = self.analyzer.analyze_directory(".", ['.md', '.py', '.txt', '.json'])
        print(f"âœ“ åˆ†æå®Œæˆï¼ç™¼ç¾ {self.current_results['unique_characters']} å€‹å”¯ä¸€å­—ç¬¦")
        print(f"âœ“ Analysis complete! Found {self.current_results['unique_characters']} unique characters")
        
    def show_summary(self):
        """é¡¯ç¤ºç¸½çµ (Show summary)"""
        if not self.current_results:
            print("âŒ è«‹å…ˆåˆ†æå­˜å„²åº« (Please analyze repository first)")
            return
            
        print("\n" + "="*60)
        print("ğŸ“Š å­—ç¬¦åˆ†æç¸½çµ (Character Analysis Summary)")
        print("="*60)
        print(f"ğŸ“ åˆ†ææ–‡ä»¶æ•¸: {self.current_results['total_files']}")
        print(f"ğŸ“ ç¸½å­—ç¬¦æ•¸: {self.current_results['total_characters']:,}")
        print(f"ğŸ”¤ å”¯ä¸€å­—ç¬¦æ•¸: {self.current_results['unique_characters']:,}")
        
        print("\nğŸ“š æ›¸å¯«ç³»çµ±åˆ†å¸ƒ (Writing System Distribution):")
        ws_counts = self.current_results['writing_systems']
        total = sum(ws_counts.values())
        
        for ws, count in sorted(ws_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / total * 100) if total > 0 else 0
            ws_name = ws.value if hasattr(ws, 'value') else str(ws)
            bar = "â–ˆ" * min(int(percentage / 2), 50)
            print(f"  {ws_name:12} {count:6,} ({percentage:5.1f}%) {bar}")
    
    def show_top_characters(self, limit: int = 20):
        """é¡¯ç¤ºæœ€å¸¸ç”¨å­—ç¬¦ (Show top characters)"""
        print(f"\nğŸ† æœ€å¸¸ç”¨ {limit} å€‹å­—ç¬¦ (Top {limit} Characters):")
        print("-" * 80)
        
        for i, (char, freq) in enumerate(self.analyzer.character_frequency.most_common(limit), 1):
            if not char.isspace():
                char_info = self.analyzer.get_character_info(char)
                ws_icon = self._get_writing_system_icon(char_info.writing_system)
                print(f"{i:2d}. '{char}' {ws_icon} U+{char_info.unicode_codepoint:04X} "
                      f"({freq:,} times) - {char_info.unicode_name[:50]}")
    
    def _get_writing_system_icon(self, ws: WritingSystem) -> str:
        """ç²å–æ›¸å¯«ç³»çµ±åœ–æ¨™ (Get writing system icon)"""
        icons = {
            WritingSystem.LATIN: "ğŸ”¤",
            WritingSystem.CJK: "ğŸ€„",
            WritingSystem.ARABIC: "ğŸ”—",
            WritingSystem.HEBREW: "ğŸ”¯",
            WritingSystem.CYRILLIC: "ğŸ‡·ğŸ‡º",
            WritingSystem.GREEK: "ğŸ‡¬ğŸ‡·",
            WritingSystem.DEVANAGARI: "ğŸ‡®ğŸ‡³",
            WritingSystem.PUNCTUATION: "â—",
            WritingSystem.SYMBOLS: "ğŸ”£",
            WritingSystem.DIGITS: "ğŸ”¢",
            WritingSystem.OTHER: "â“"
        }
        return icons.get(ws, "â“")
    
    def search_characters(self, query: str = None, writing_system: str = None, limit: int = 10):
        """æœç´¢å­—ç¬¦ (Search characters)"""
        ws = None
        if writing_system:
            try:
                ws = WritingSystem(writing_system)
            except ValueError:
                print(f"âŒ ç„¡æ•ˆçš„æ›¸å¯«ç³»çµ±: {writing_system}")
                print("å¯ç”¨çš„æ›¸å¯«ç³»çµ±:", [ws.value for ws in WritingSystem])
                return
        
        results = self.analyzer.search_characters(query, ws, min_frequency=1)
        
        if not results:
            print("âŒ æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„å­—ç¬¦ (No matching characters found)")
            return
        
        print(f"\nğŸ” æœç´¢çµæœ (Search Results) - é¡¯ç¤ºå‰ {limit} å€‹:")
        print("-" * 80)
        
        for i, char_info in enumerate(results[:limit], 1):
            ws_icon = self._get_writing_system_icon(char_info.writing_system)
            print(f"{i:2d}. '{char_info.character}' {ws_icon} U+{char_info.unicode_codepoint:04X} "
                  f"({char_info.frequency:,} times)")
            print(f"    åç¨±: {char_info.unicode_name}")
            print(f"    é¡åˆ¥: {char_info.category}")
            print(f"    æ›¸å¯«ç³»çµ±: {char_info.writing_system.value}")
            print()
    
    def analyze_expression_characters(self, expression: str):
        """åˆ†æè¡¨é”å¼ä¸­çš„å­—ç¬¦ (Analyze characters in expression)"""
        print(f"\nğŸ“ åˆ†æè¡¨é”å¼: '{expression}'")
        print("="*60)
        
        # Character analysis
        char_analysis = self.analyzer.analyze_text(expression, "user_input")
        print(f"å­—ç¬¦ç¸½æ•¸: {char_analysis['total_characters']}")
        print(f"å”¯ä¸€å­—ç¬¦æ•¸: {char_analysis['unique_characters']}")
        
        print("\nå­—ç¬¦è©³æƒ…:")
        for char, char_info in char_analysis['character_infos'].items():
            ws_icon = self._get_writing_system_icon(char_info.writing_system)
            print(f"  '{char}' {ws_icon} U+{char_info.unicode_codepoint:04X} - {char_info.unicode_name}")
        
        print(f"\næ›¸å¯«ç³»çµ±åˆ†å¸ƒ:")
        for ws, count in char_analysis['writing_systems'].items():
            print(f"  {ws}: {count}")
        
        # Human expression evaluation
        try:
            context = ExpressionContext()
            eval_result = self.expression_evaluator.comprehensive_evaluation(expression, context)
            print(f"\nğŸ§  äººé¡è¡¨é”è©•ä¼° (Human Expression Evaluation):")
            print(f"  æ•´é«”åˆ†æ•¸: {eval_result['integrated']['overall_score']:.3f}")
            print(f"  å½¢å¼èªç¾©: {eval_result['formal_semantic']['score']:.3f}")
            print(f"  èªçŸ¥è™•ç†: {eval_result['cognitive']['score']:.3f}")
            print(f"  ç¤¾æœƒé©ç•¶: {eval_result['social']['score']:.3f}")
        except Exception as e:
            print(f"âš ï¸  è¡¨é”è©•ä¼°å‡ºéŒ¯: {e}")
    
    def export_character_data(self, filename: str = "character_data.csv"):
        """å°å‡ºå­—ç¬¦æ•¸æ“š (Export character data)"""
        try:
            df = self.analyzer.create_character_dataframe()
            df.to_csv(filename, index=False, encoding='utf-8')
            print(f"âœ“ å­—ç¬¦æ•¸æ“šå·²å°å‡ºåˆ° {filename}")
            print(f"âœ“ Character data exported to {filename}")
            
            # Show preview
            print(f"\né è¦½å‰5è¡Œ (Preview first 5 rows):")
            print(df.head().to_string())
            
        except Exception as e:
            print(f"âŒ å°å‡ºå¤±æ•—: {e}")
    
    def interactive_mode(self):
        """äº’å‹•æ¨¡å¼ (Interactive mode)"""
        print("ğŸš€ æ­¡è¿ä½¿ç”¨æˆ‘çš„å­—ç¬¦ç€è¦½å™¨ï¼")
        print("ğŸš€ Welcome to My Characters Browser!")
        print("\nå¯ç”¨å‘½ä»¤ (Available commands):")
        print("  summary, s     - é¡¯ç¤ºç¸½çµ")
        print("  top [N]        - é¡¯ç¤ºæœ€å¸¸ç”¨Nå€‹å­—ç¬¦ (é»˜èª20)")
        print("  search [query] - æœç´¢å­—ç¬¦")
        print("  analyze [text] - åˆ†ææ–‡æœ¬å­—ç¬¦")
        print("  export [file]  - å°å‡ºå­—ç¬¦æ•¸æ“š")
        print("  help, h        - é¡¯ç¤ºå¹«åŠ©")
        print("  quit, q        - é€€å‡º")
        
        if not self.current_results:
            self.load_repository_analysis()
        
        while True:
            try:
                cmd = input("\nğŸ”¤ > ").strip().split()
                if not cmd:
                    continue
                
                command = cmd[0].lower()
                
                if command in ['quit', 'q']:
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                elif command in ['help', 'h']:
                    print("å¯ç”¨å‘½ä»¤ (Available commands):")
                    print("  summary, s     - é¡¯ç¤ºç¸½çµ")
                    print("  top [N]        - é¡¯ç¤ºæœ€å¸¸ç”¨Nå€‹å­—ç¬¦")
                    print("  search [query] - æœç´¢å­—ç¬¦")
                    print("  analyze [text] - åˆ†ææ–‡æœ¬å­—ç¬¦")
                    print("  export [file]  - å°å‡ºå­—ç¬¦æ•¸æ“š")
                elif command in ['summary', 's']:
                    self.show_summary()
                elif command == 'top':
                    limit = int(cmd[1]) if len(cmd) > 1 else 20
                    self.show_top_characters(limit)
                elif command == 'search':
                    query = ' '.join(cmd[1:]) if len(cmd) > 1 else None
                    self.search_characters(query)
                elif command == 'analyze':
                    if len(cmd) > 1:
                        text = ' '.join(cmd[1:])
                        self.analyze_expression_characters(text)
                    else:
                        print("âŒ è«‹æä¾›è¦åˆ†æçš„æ–‡æœ¬")
                elif command == 'export':
                    filename = cmd[1] if len(cmd) > 1 else "character_data.csv"
                    self.export_character_data(filename)
                else:
                    print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
                    print("è¼¸å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è¦‹ï¼")
                break
            except Exception as e:
                print(f"âŒ éŒ¯èª¤: {e}")


def main():
    """ä¸»å‡½æ•¸ (Main function)"""
    parser = argparse.ArgumentParser(description="æˆ‘çš„å­—ç¬¦ç€è¦½å™¨ (My Characters Browser)")
    parser.add_argument('--summary', action='store_true', help='é¡¯ç¤ºå­—ç¬¦ç¸½çµ')
    parser.add_argument('--top', type=int, default=20, help='é¡¯ç¤ºæœ€å¸¸ç”¨å­—ç¬¦æ•¸é‡')
    parser.add_argument('--search', type=str, help='æœç´¢å­—ç¬¦')
    parser.add_argument('--analyze', type=str, help='åˆ†ææ–‡æœ¬å­—ç¬¦')
    parser.add_argument('--export', type=str, help='å°å‡ºå­—ç¬¦æ•¸æ“šåˆ°æ–‡ä»¶')
    parser.add_argument('--interactive', '-i', action='store_true', help='é€²å…¥äº’å‹•æ¨¡å¼')
    
    args = parser.parse_args()
    
    browser = CharacterBrowser()
    
    # Load analysis if any command requires it
    if any([args.summary, args.top, args.search, args.analyze, args.export, args.interactive]):
        browser.load_repository_analysis()
    
    # Execute commands
    if args.summary:
        browser.show_summary()
    
    if args.top:
        browser.show_top_characters(args.top)
    
    if args.search:
        browser.search_characters(args.search)
    
    if args.analyze:
        browser.analyze_expression_characters(args.analyze)
    
    if args.export:
        browser.export_character_data(args.export)
    
    if args.interactive or len(sys.argv) == 1:
        browser.interactive_mode()


if __name__ == "__main__":
    main()