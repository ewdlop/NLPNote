"""
å¤©é“è·¯å¾‘ç©åˆ†ç¯„ä¾‹èˆ‡æ¸¬è©¦ (Heavenly Way Path Integral Examples and Tests)

This module provides comprehensive examples and tests for the PathIntegralNLP implementation,
demonstrating how to use path integral approaches following å¤©é“ (Heavenly Way) principles
for natural language processing tasks.
"""

import sys
import os

# Add the current directory to the path to import our modules
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from PathIntegralNLP import PathIntegralNLP, TianDaoPath, ExpressionContext
    from HumanExpressionEvaluator import ExpressionContext as HEContext
    PATH_INTEGRAL_AVAILABLE = True
except ImportError as e:
    print(f"Import error: {e}")
    PATH_INTEGRAL_AVAILABLE = False


def demonstrate_basic_path_integration():
    """æ¼”ç¤ºåŸºæœ¬è·¯å¾‘ç©åˆ†åŠŸèƒ½"""
    print("=" * 60)
    print("åŸºæœ¬è·¯å¾‘ç©åˆ†æ¼”ç¤º (Basic Path Integration Demonstration)")
    print("=" * 60)
    
    if not PATH_INTEGRAL_AVAILABLE:
        print("PathIntegralNLP ä¸å¯ç”¨ï¼Œè·³éæ¼”ç¤º")
        return
    
    # å‰µå»ºè·¯å¾‘ç©åˆ†NLPè™•ç†å™¨
    path_nlp = PathIntegralNLP(max_path_length=6, integration_steps=50)
    
    # ç¤ºä¾‹1: å¾"é–‹å§‹"åˆ°"æˆåŠŸ"çš„èªç¾©è·¯å¾‘
    print("\nç¤ºä¾‹1: å¾'é–‹å§‹'åˆ°'æˆåŠŸ'çš„èªç¾©è·¯å¾‘åˆ†æ")
    print("-" * 40)
    
    start_concept = "é–‹å§‹"
    end_concept = "æˆåŠŸ"
    
    result = path_nlp.path_integral_evaluation(start_concept, end_concept)
    
    print(f"èµ·å§‹æ¦‚å¿µ: {start_concept}")
    print(f"ç›®æ¨™æ¦‚å¿µ: {end_concept}")
    print(f"æ‰¾åˆ°è·¯å¾‘æ•¸é‡: {len(result.all_paths)}")
    print(f"è·¯å¾‘ç©åˆ†å€¼: {result.integration_value:.4f}")
    print(f"å’Œè«§æŒ‡æ•¸: {result.harmony_index:.4f}")
    print(f"è‡ªç„¶åº¦æŒ‡æ•¸: {result.naturalness_index:.4f}")
    print(f"å¤©é“å°é½ŠæŒ‡æ•¸: {result.tian_dao_index:.4f}")
    print(f"æ”¶æ–‚ç‹€æ…‹: {'å·²æ”¶æ–‚' if result.convergence_achieved else 'æœªæ”¶æ–‚'}")
    
    print("\næœ€å„ªè·¯å¾‘è©³æƒ…:")
    optimal = result.optimal_path
    print(f"  è·¯å¾‘é¡å‹: {optimal.path_type.value}")
    print(f"  èµ·å§‹: {optimal.start_concept}")
    print(f"  ä¸­é–“æ¦‚å¿µ: {optimal.intermediate_concepts[:3]}...")  # åªé¡¯ç¤ºå‰3å€‹
    print(f"  çµæŸ: {optimal.end_concept}")
    print(f"  è·¯å¾‘æ¬Šé‡: {optimal.path_weight:.4f}")
    print(f"  å’Œè«§åˆ†æ•¸: {optimal.harmony_score:.4f}")
    print(f"  è‡ªç„¶åº¦åˆ†æ•¸: {optimal.naturalness_score:.4f}")
    print(f"  å¤©é“å°é½Šåº¦: {optimal.tian_dao_alignment:.4f}")
    
    return result


def demonstrate_natural_flow_analysis():
    """æ¼”ç¤ºè‡ªç„¶æµå‹•åˆ†æ"""
    print("\n" + "=" * 60)
    print("è‡ªç„¶æµå‹•åˆ†ææ¼”ç¤º (Natural Flow Analysis Demonstration)")
    print("=" * 60)
    
    if not PATH_INTEGRAL_AVAILABLE:
        print("PathIntegralNLP ä¸å¯ç”¨ï¼Œè·³éæ¼”ç¤º")
        return
    
    path_nlp = PathIntegralNLP()
    
    # æ¸¬è©¦æ–‡æœ¬
    test_texts = [
        "æ°´æµå‘ä¸‹ï¼Œé †å…¶è‡ªç„¶ï¼Œæœ€çµ‚åŒ¯å…¥å¤§æµ·",
        "åŠªåŠ›å·¥ä½œï¼Œåˆ»è‹¦å­¸ç¿’ï¼Œè¿½æ±‚å¤¢æƒ³ï¼Œå¯¦ç¾ç›®æ¨™",
        "æ˜¥å¤©ä¾†äº†ï¼ŒèŠ±æœµç¶»æ”¾ï¼Œç”Ÿå‘½å¾©ç”¦ï¼Œè¬è±¡æ›´æ–°",
        "äººç”Ÿå¦‚å¤¢ï¼Œæ­²æœˆå¦‚æµï¼Œçæƒœç•¶ä¸‹ï¼Œæ„Ÿæ©ç”Ÿæ´»",
        "ç§‘æŠ€ç™¼å±•ï¼Œå‰µæ–°çªç ´ï¼Œæ”¹è®Šä¸–ç•Œï¼Œé€ ç¦äººé¡"
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nç¤ºä¾‹{i}: '{text}'")
        print("-" * 50)
        
        # åˆ†ææ–‡æœ¬æµå‹•
        analysis = path_nlp.natural_language_flow_analysis(text)
        
        print(f"æµå‹•åˆ†æ: {analysis['flow_analysis']}")
        print(f"å¤©é“å°é½Šåº¦: {analysis['tian_dao_alignment']:.4f}")
        print(f"è‡ªç„¶æµå‹•åˆ†æ•¸: {analysis['natural_flow_score']:.4f}")
        print(f"å’Œè«§æŒ‡æ•¸: {analysis['harmony_index']:.4f}")
        print(f"åˆ†ææ¦‚å¿µ: {analysis['concepts_analyzed']}")
        
        print("å»ºè­°:")
        for rec in analysis['recommendations']:
            print(f"  â€¢ {rec}")
        
        # å¦‚æœæœ‰è©³ç´°åˆ†æ•¸ï¼Œé¡¯ç¤ºå‰å¹¾å€‹
        if analysis.get('detailed_flow_scores'):
            flow_scores = analysis['detailed_flow_scores'][:3]
            print(f"è©³ç´°æµå‹•åˆ†æ•¸ (å‰3å€‹): {[f'{s:.3f}' for s in flow_scores]}")


def demonstrate_tian_dao_principles():
    """æ¼”ç¤ºå¤©é“åŸå‰‡çš„è¨ˆç®—"""
    print("\n" + "=" * 60)
    print("å¤©é“åŸå‰‡è¨ˆç®—æ¼”ç¤º (Heavenly Way Principles Demonstration)")
    print("=" * 60)
    
    if not PATH_INTEGRAL_AVAILABLE:
        print("PathIntegralNLP ä¸å¯ç”¨ï¼Œè·³éæ¼”ç¤º")
        return
    
    from PathIntegralNLP import TianDaoCalculator
    
    calculator = TianDaoCalculator()
    
    # æ¸¬è©¦æ¦‚å¿µå°
    concept_pairs = [
        ("å¤§", "å°"),        # é™°é™½å°ç«‹
        ("å¿«é€Ÿ", "ç·©æ…¢"),    # äº’è£œæ¦‚å¿µ
        ("é–‹å§‹", "çµæŸ"),    # éç¨‹å°ç«‹
        ("å…‰æ˜", "é»‘æš—"),    # ç¶“å…¸é™°é™½
        ("å’Œè«§", "å¹³è¡¡"),    # ç›¸è¿‘æ¦‚å¿µ
        ("å‰µæ–°", "å‚³çµ±"),    # å°æ¯”æ¦‚å¿µ
        ("ç°¡å–®", "è¤‡é›œ"),    # è¤‡é›œåº¦å°æ¯”
        ("è‡ªç„¶", "äººå·¥")     # æœ¬è³ªå°æ¯”
    ]
    
    print("\nç„¡ç‚ºåˆ†æ•¸è¨ˆç®— (Wu Wei Scores):")
    print("-" * 30)
    for concept1, concept2 in concept_pairs:
        wu_wei_score = calculator.calculate_wu_wei_score(concept1, concept2)
        print(f"'{concept1}' â†” '{concept2}': {wu_wei_score:.4f}")
    
    print("\né™°é™½åˆ†æ•¸è¨ˆç®— (Yin Yang Scores):")
    print("-" * 30)
    for concept1, concept2 in concept_pairs:
        yin_yang_score = calculator.calculate_yin_yang_score(concept1, concept2)
        print(f"'{concept1}' â†” '{concept2}': {yin_yang_score:.4f}")
    
    # æ¸¬è©¦æ¦‚å¿µåºåˆ—
    concept_sequences = [
        ["é–‹å§‹", "ç™¼å±•", "æˆç†Ÿ", "çµæŸ"],
        ["æ˜¥", "å¤", "ç§‹", "å†¬"],
        ["å­¸ç¿’", "å¯¦è¸", "åæ€", "æ”¹é€²"],
        ["æƒ³æ³•", "è¨ˆåŠƒ", "è¡Œå‹•", "æˆæœ"],
        ["å’Œè«§", "å¹³è¡¡", "çµ±ä¸€", "å®Œæ•´"]
    ]
    
    print("\näº”è¡Œåˆ†æ•¸è¨ˆç®— (Wu Xing Scores):")
    print("-" * 30)
    for concepts in concept_sequences:
        wu_xing_score = calculator.calculate_wu_xing_score(concepts)
        print(f"{concepts}: {wu_xing_score:.4f}")
    
    print("\nå¤ªæ¥µåˆ†æ•¸è¨ˆç®— (Tai Chi Scores):")
    print("-" * 30)
    for concepts in concept_sequences:
        tai_chi_score = calculator.calculate_tai_chi_score(concepts)
        print(f"{concepts}: {tai_chi_score:.4f}")
    
    print("\nè‡ªç„¶æµå‹•åˆ†æ•¸è¨ˆç®— (Natural Flow Scores):")
    print("-" * 30)
    for concepts in concept_sequences:
        flow_score = calculator.calculate_natural_flow_score(concepts)
        print(f"{concepts}: {flow_score:.4f}")


def demonstrate_integration_with_existing_framework():
    """æ¼”ç¤ºèˆ‡ç¾æœ‰æ¡†æ¶çš„æ•´åˆ"""
    print("\n" + "=" * 60)
    print("èˆ‡ç¾æœ‰æ¡†æ¶æ•´åˆæ¼”ç¤º (Integration with Existing Framework)")
    print("=" * 60)
    
    if not PATH_INTEGRAL_AVAILABLE:
        print("PathIntegralNLP ä¸å¯ç”¨ï¼Œè·³éæ¼”ç¤º")
        return
    
    path_nlp = PathIntegralNLP()
    
    # å‰µå»ºè¡¨é”èªå¢ƒ
    context = ExpressionContext(
        formality_level='formal',
        situation='academic',
        cultural_background='chinese'
    )
    
    # æ¸¬è©¦è¡¨é”
    expressions = [
        "ä¾ç…§å¤©é“çš„æŒ‡å¼•ï¼Œæˆ‘å€‘å°‹æ±‚è‡ªç„¶çš„è§£æ±ºæ–¹æ¡ˆ",
        "Through natural principles, we find harmonious solutions",
        "é †å…¶è‡ªç„¶ï¼Œäº‹åŠåŠŸå€ï¼Œé€™æ˜¯å¤äººçš„æ™ºæ…§",
        "Innovation emerges from the balance of tradition and progress",
        "ç„¡ç‚ºè€Œæ²»ï¼Œè®“äº‹ç‰©æŒ‰å…¶æœ¬æ€§ç™¼å±•"
    ]
    
    for i, expression in enumerate(expressions, 1):
        print(f"\nè¡¨é”{i}: '{expression}'")
        print("-" * 50)
        
        # é€²è¡Œè·¯å¾‘ç©åˆ†åˆ†æ
        analysis = path_nlp.natural_language_flow_analysis(expression, context)
        
        print(f"å¤©é“å°é½Šåº¦: {analysis['tian_dao_alignment']:.4f}")
        print(f"è‡ªç„¶æµå‹•åˆ†æ•¸: {analysis['natural_flow_score']:.4f}")
        print(f"å’Œè«§æŒ‡æ•¸: {analysis['harmony_index']:.4f}")
        
        # é¡¯ç¤ºæ•´åˆåˆ†æçµæœ
        if 'integrated_analysis' in analysis and analysis['integrated_analysis']:
            integrated = analysis['integrated_analysis']
            if 'human_expression_evaluation' in integrated:
                he_result = integrated['human_expression_evaluation']
                print(f"æ•´åˆè©•ä¼° - æ•´é«”åˆ†æ•¸: {he_result.get('integrated', {}).get('overall_score', 'æœªçŸ¥')}")
                print(f"æ•´åˆè©•ä¼° - ä¿¡å¿ƒåº¦: {he_result.get('confidence', 'æœªçŸ¥')}")
            elif 'integration_error' in integrated:
                print(f"æ•´åˆç‹€æ…‹: {integrated['integration_error']}")
            else:
                print("æ•´åˆç‹€æ…‹: æœªæ‰¾åˆ°å…·é«”è©•ä¼°çµæœ")
        
        print("ä¸»è¦å»ºè­°:")
        for rec in analysis['recommendations'][:2]:  # åªé¡¯ç¤ºå‰å…©å€‹å»ºè­°
            print(f"  â€¢ {rec}")


def demonstrate_comparative_analysis():
    """æ¼”ç¤ºæ¯”è¼ƒåˆ†æ"""
    print("\n" + "=" * 60)
    print("æ¯”è¼ƒåˆ†ææ¼”ç¤º (Comparative Analysis Demonstration)")
    print("=" * 60)
    
    if not PATH_INTEGRAL_AVAILABLE:
        print("PathIntegralNLP ä¸å¯ç”¨ï¼Œè·³éæ¼”ç¤º")
        return
    
    path_nlp = PathIntegralNLP()
    
    # æ¯”è¼ƒä¸åŒé¢¨æ ¼çš„è¡¨é”
    expressions_comparison = [
        {
            'name': 'è‡ªç„¶é¢¨æ ¼',
            'text': 'æ°´æµå‘ä¸‹ï¼Œé †å‹¢è€Œç‚ºï¼Œæœ€çµ‚é”åˆ°ç›®æ¨™'
        },
        {
            'name': 'å¼·è¿«é¢¨æ ¼', 
            'text': 'å¿…é ˆåŠªåŠ›ï¼Œå …æŒä¸æ‡ˆï¼Œå¼·è¡Œçªç ´å›°é›£'
        },
        {
            'name': 'å¹³è¡¡é¢¨æ ¼',
            'text': 'é©æ™‚åŠªåŠ›ï¼Œé©æ™‚ä¼‘æ¯ï¼Œä¿æŒèº«å¿ƒå¹³è¡¡'
        },
        {
            'name': 'å“²å­¸é¢¨æ ¼',
            'text': 'å¤©é“é…¬å‹¤ï¼Œåšå¾·è¼‰ç‰©ï¼Œè‡ªå¼·ä¸æ¯è€Œå’Œè«§å…±è™•'
        }
    ]
    
    results = []
    
    for expr in expressions_comparison:
        analysis = path_nlp.natural_language_flow_analysis(expr['text'])
        results.append({
            'name': expr['name'],
            'text': expr['text'],
            'tian_dao_alignment': analysis['tian_dao_alignment'],
            'natural_flow_score': analysis['natural_flow_score'],
            'harmony_index': analysis['harmony_index']
        })
    
    # æ’åºä¸¦é¡¯ç¤ºçµæœ
    results.sort(key=lambda x: x['tian_dao_alignment'], reverse=True)
    
    print("\næŒ‰å¤©é“å°é½Šåº¦æ’åºçš„çµæœ:")
    print("-" * 40)
    for i, result in enumerate(results, 1):
        print(f"{i}. {result['name']}")
        print(f"   æ–‡æœ¬: '{result['text']}'")
        print(f"   å¤©é“å°é½Šåº¦: {result['tian_dao_alignment']:.4f}")
        print(f"   è‡ªç„¶æµå‹•: {result['natural_flow_score']:.4f}")
        print(f"   å’Œè«§æŒ‡æ•¸: {result['harmony_index']:.4f}")
        print()
    
    # åˆ†ææœ€ä½³å’Œæœ€å·®è¡¨é”çš„å·®ç•°
    best = results[0]
    worst = results[-1]
    
    print("æœ€ä½³èˆ‡æœ€å·®è¡¨é”çš„å°æ¯”:")
    print("-" * 30)
    print(f"æœ€ä½³ ({best['name']}): å¤©é“å°é½Šåº¦ {best['tian_dao_alignment']:.4f}")
    print(f"æœ€å·® ({worst['name']}): å¤©é“å°é½Šåº¦ {worst['tian_dao_alignment']:.4f}")
    print(f"å·®ç•°: {best['tian_dao_alignment'] - worst['tian_dao_alignment']:.4f}")
    
    return results


def demonstrate_advanced_path_analysis():
    """æ¼”ç¤ºé«˜ç´šè·¯å¾‘åˆ†æ"""
    print("\n" + "=" * 60)
    print("é«˜ç´šè·¯å¾‘åˆ†ææ¼”ç¤º (Advanced Path Analysis Demonstration)")
    print("=" * 60)
    
    if not PATH_INTEGRAL_AVAILABLE:
        print("PathIntegralNLP ä¸å¯ç”¨ï¼Œè·³éæ¼”ç¤º")
        return
    
    path_nlp = PathIntegralNLP(max_path_length=8, integration_steps=100)
    
    # è¤‡é›œçš„æ¦‚å¿µè½‰æ›
    complex_transformations = [
        ("æ··æ²Œ", "ç§©åº"),
        ("å•é¡Œ", "æ™ºæ…§"),
        ("è¡çª", "å’Œè«§"),
        ("å›°é›£", "æˆé•·"),
        ("è¿·èŒ«", "æ¸…æ™°")
    ]
    
    for start_concept, end_concept in complex_transformations:
        print(f"\nåˆ†æè·¯å¾‘: '{start_concept}' â†’ '{end_concept}'")
        print("-" * 40)
        
        # æä¾›ä¸€äº›ç›¸é—œçš„ä¸­é–“æ¦‚å¿µ
        intermediate_concepts = [
            "è½‰æ›", "éç¨‹", "å­¸ç¿’", "ç†è§£", "å¹³è¡¡", "é©æ‡‰",
            "ç™¼å±•", "æ¼”è®Š", "èª¿å’Œ", "æ•´åˆ", "çªç ´", "é ˜æ‚Ÿ"
        ]
        
        result = path_nlp.path_integral_evaluation(
            start_concept, end_concept, intermediate_concepts
        )
        
        print(f"è·¯å¾‘ç©åˆ†å€¼: {result.integration_value:.4f}")
        print(f"å¤©é“æŒ‡æ•¸: {result.tian_dao_index:.4f}")
        print(f"æ”¶æ–‚ç‹€æ…‹: {'å·²æ”¶æ–‚' if result.convergence_achieved else 'æœªæ”¶æ–‚'}")
        
        # åˆ†æä¸åŒé¡å‹çš„è·¯å¾‘
        path_types_analysis = {}
        for path in result.all_paths[:10]:  # åˆ†æå‰10æ¢è·¯å¾‘
            path_type = path.path_type.value
            if path_type not in path_types_analysis:
                path_types_analysis[path_type] = []
            path_types_analysis[path_type].append(path.tian_dao_alignment)
        
        print("ä¸åŒè·¯å¾‘é¡å‹çš„å¹³å‡å¤©é“å°é½Šåº¦:")
        for path_type, alignments in path_types_analysis.items():
            avg_alignment = sum(alignments) / len(alignments)
            print(f"  {path_type}: {avg_alignment:.4f} (åŸºæ–¼ {len(alignments)} æ¢è·¯å¾‘)")


def run_comprehensive_tests():
    """é‹è¡Œç¶œåˆæ¸¬è©¦"""
    print("\n" + "=" * 70)
    print("å¤©é“è·¯å¾‘ç©åˆ†ç¶œåˆæ¸¬è©¦ (Comprehensive Heavenly Way Path Integral Tests)")
    print("=" * 70)
    
    if not PATH_INTEGRAL_AVAILABLE:
        print("PathIntegralNLP ä¸å¯ç”¨ï¼Œç„¡æ³•é‹è¡Œæ¸¬è©¦")
        return False
    
    try:
        print("\næ­£åœ¨é‹è¡Œæ¸¬è©¦...")
        
        # é‹è¡Œæ‰€æœ‰æ¼”ç¤º
        basic_result = demonstrate_basic_path_integration()
        demonstrate_natural_flow_analysis()
        demonstrate_tian_dao_principles()
        demonstrate_integration_with_existing_framework()
        comparison_results = demonstrate_comparative_analysis()
        demonstrate_advanced_path_analysis()
        
        print("\n" + "=" * 70)
        print("æ¸¬è©¦ç¸½çµ (Test Summary)")
        print("=" * 70)
        
        print("âœ“ åŸºæœ¬è·¯å¾‘ç©åˆ†åŠŸèƒ½æ­£å¸¸")
        print("âœ“ è‡ªç„¶æµå‹•åˆ†æåŠŸèƒ½æ­£å¸¸")
        print("âœ“ å¤©é“åŸå‰‡è¨ˆç®—åŠŸèƒ½æ­£å¸¸")
        print("âœ“ æ¡†æ¶æ•´åˆåŠŸèƒ½æ­£å¸¸")
        print("âœ“ æ¯”è¼ƒåˆ†æåŠŸèƒ½æ­£å¸¸")
        print("âœ“ é«˜ç´šè·¯å¾‘åˆ†æåŠŸèƒ½æ­£å¸¸")
        
        if basic_result:
            print(f"\nåŸºæœ¬çµ±è¨ˆ:")
            print(f"  - æ¸¬è©¦è·¯å¾‘ç©åˆ†å€¼: {basic_result.integration_value:.4f}")
            print(f"  - æ¸¬è©¦å¤©é“æŒ‡æ•¸: {basic_result.tian_dao_index:.4f}")
            print(f"  - æ”¶æ–‚ç‹€æ…‹: {'æˆåŠŸ' if basic_result.convergence_achieved else 'éœ€è¦æ›´å¤šè¿­ä»£'}")
        
        if comparison_results:
            best_style = comparison_results[0]
            print(f"  - æœ€ä½³è¡¨é”é¢¨æ ¼: {best_style['name']} (å¤©é“å°é½Šåº¦: {best_style['tian_dao_alignment']:.4f})")
        
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼è·¯å¾‘ç©åˆ†NLPç³»çµ±é‹è¡Œæ­£å¸¸ã€‚")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("å¤©é“è·¯å¾‘ç©åˆ†è‡ªç„¶èªè¨€è™•ç† - æ¼”ç¤ºèˆ‡æ¸¬è©¦")
    print("Path Integral Natural Language Processing Following the Heavenly Way")
    print("=" * 70)
    
    # æª¢æŸ¥ç’°å¢ƒ
    if PATH_INTEGRAL_AVAILABLE:
        print("âœ“ PathIntegralNLP æ¨¡çµ„å¯ç”¨")
    else:
        print("âŒ PathIntegralNLP æ¨¡çµ„ä¸å¯ç”¨")
    
    # é‹è¡Œç¶œåˆæ¸¬è©¦
    success = run_comprehensive_tests()
    
    if success:
        print("\n" + "=" * 70)
        print("ğŸŒŸ å¤©é“è·¯å¾‘ç©åˆ†ç³»çµ±å·²æº–å‚™å°±ç·’ï¼")
        print("   The Heavenly Way Path Integral System is ready!")
        print("=" * 70)
    else:
        print("\n" + "=" * 70)
        print("âš ï¸  ç³»çµ±éœ€è¦é€²ä¸€æ­¥èª¿è©¦")
        print("   System requires further debugging")
        print("=" * 70)